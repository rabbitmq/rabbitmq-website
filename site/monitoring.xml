<?xml-stylesheet type="text/xml" href="page.xsl"?>
<!DOCTYPE html [
<!ENTITY % entities SYSTEM "rabbit.ent">
%entities;
]>
<!--
Copyright (c) 2007-2017 Pivotal Software, Inc.

All rights reserved. This program and the accompanying materials
are made available under the terms of the under the Apache License,
Version 2.0 (the "Licenseâ€); you may not use this file except in compliance
with the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->

<html xmlns="http://www.w3.org/1999/xhtml" xmlns:doc="http://www.rabbitmq.com/namespaces/ad-hoc/doc">
  <head>
    <title>Monitoring</title>
  </head>
  <body show-in-this-page="true">
    <doc:section name="overview">
      <doc:heading>Overview</doc:heading>

      <p class="intro">
        This document provides an overview of topics related to RabbitMQ monitoring.

        Many aspects of the system can be monitored. This guide will group them into a handful of
        categories:

        <ul>
          <li><a href="#system-metrics">Infrastructure and kernel metrics</a></li>
          <li>
            <a href="#rabbitmq-metrics">RabbitMQ metrics</a> which can be further split
            into

            <ul>
              <li>Cluster-wide metrics</li>
              <li><a href="#node-metrics">Node metrics</a></li>
              <li><a href="#queue-metrics">Queue metrics</a></li>
            </ul>
          </li>
        </ul>
      </p>

      <p>
        Monitoring your RabbitMQ installation is an effective means to detect issues before they affect
        the rest of your environment and, eventually, your users.
      </p>
    </doc:section>

    <doc:section name="system-metrics">
      <doc:heading>Infrastructure and Kernel Metrics</doc:heading>

      <p>
        First step towards a useful monitoring system starts with infrastructure and
        kernel metrics. There are quite a few of them but some are more important than others.
        The following metrics should be monitored on all nodes in a RabbitMQ cluster and, if possible,
        all nodes that host applications:

        <ul>
          <li>CPU stats (idle, user, system, iowait)</li>
          <li>Memory usage (free, cached, buffered)</li>
          <li>Disk I/O (reads &amp; writes per unit time, I/O wait percentages)</li>
          <li>Free disk space</li>
          <li>File descriptors used by <code>beam.smp</code> vs. <a href="/networking.html#open-file-handle-limit">max system limit</a></li>
          <li>TCP connections by state (<code>ESTABLISHED</code>, <code>CLOSE_WAIT</code>, <code>TIME_WAIT</code>)</li>
          <li>Network throughput (bytes received, bytes sent) vs. maximum network link throughput</li>
          <li><a href="https://www.kernel.org/doc/Documentation/sysctl/vm.txt">VM</a> statistics (dirty page flushes, writeback volume)</li>
          <li>System load average (<code>/proc/loadavg</code>)</li>
        </ul>
      </p>

      <p>
        There is no shortage of existing tools (such as Graphite or Datadog) that collect infrastructure
        and kernel metrics, store and visualise them over periods of time.
      </p>
    </doc:section>

    <doc:section name="rabbitmq-metrics">
      <doc:heading>RabbitMQ Metrics</doc:heading>
      <p>
        The RabbitMQ <a href="management.html">management plugin</a> provides a starting point for
        monitoring RabbitMQ metrics. One limitation, however, is that only up to one day's worth of
        metrics are stored. Collecting and storing metrics for the long term is important for anomaly detection,
        root cause analysis and capacity planning.
      </p>

      <p>
        It is recommended that metrics are collected at 60 second intervals (or at least 30 second intervals if higher update rate
        is desired). More frequent collection will increase load and the system and provide no practical benefits for monitoring systems.
      </p>

      <doc:subsection name="node-metrics">
        <doc:heading>Node Metrics</doc:heading>
        <p>
          Node metrics are made available through the <a href="management.html#http-api">HTTP API</a>
          via the <a href="https://cdn.rawgit.com/rabbitmq/rabbitmq-management/&version-server-tag;/priv/www/api/index.html"><code>api/nodes/<i>name</i></code></a>
          endpoint.
        </p>

        <p>
          Most of the metrics represent point-in-time absolute values. Some, however, represent activity over a recent period of time
          (for example, GC runs and bytes reclaimed). The latter metrics are primarily useful when compared to their
          previous values and historical mean/percentile values.
        </p>

        <table>
          <thead>
            <tr><td>Metric</td><td>JSON field name</td></tr>
          </thead>
          <tbody>
            <tr><td>Total amount of <a href="/memory-use.html">memory used</a></td><td><code>mem_used</code></td></tr>
            <tr><td>Memory usage high watermark</td><td><code>mem_limit</code></td></tr>
            <tr><td>Is a <a href="/memory.html">memory alarm</a> in effect?</td><td><code>mem_alarm</code></td></tr>
            <tr><td>Free disk space low watermark</td><td><code>disk_free_limit</code></td></tr>
            <tr><td>Is a <a href="/disk-alarms.html">disk alarm</a> in effect?</td><td><code>disk_free_alarm</code></td></tr>
            <tr><td><a href="/networking.html#open-file-handle-limit">File descriptors available</a></td><td><code>fd_total</code></td></tr>
            <tr><td>File descriptors used</td><td><code>fd_used</code></td></tr>
            <tr><td>File descriptor open attempts</td><td><code>io_file_handle_open_attempt_count</code></td></tr>
            <tr><td>Sockets available</td><td><code>sockets_total</code></td></tr>
            <tr><td>Sockets used</td><td><code>sockets_used</code></td></tr>
            <tr><td>GC runs</td><td><code>gc_num</code></td></tr>
            <tr><td>Bytes reclaimed by GC</td><td><code>gc_bytes_reclaimed</code></td></tr>
            <tr><td>Erlang process limit</td><td><code>proc_total</code></td></tr>
            <tr><td>Erlang processes used</td><td><code>proc_used</code></td></tr>
            <tr><td>Runtime run queue</td><td><code>run_queue</code></td></tr>
            <tr>
              <td>Message stats (total, ready, <a href="/confirms.html">unacknowledged</a>)</td>
              <td><code>queue_totals.messages</code>, <code>queue_totals.ready</code>, <code>queue_totals.unacknowledged</code></td></tr>
            <tr><td>Total number of queues</td><td><code>object_totals.queues</code></td></tr>
            <tr><td>Message store disk reads</td><td><code>message_stats.disk_reads</code></td></tr>
            <tr><td>Message store disk writes</td><td><code>message_stats.disk_writes</code></td></tr>
          </tbody>
        </table>
      </doc:subsection>

      <doc:subsection name="queue-metrics">
        <doc:heading>Individual Queue Metrics</doc:heading>
        <p>
          Individual queue metrics are made available through the <a href="management.html#http-api">HTTP API</a>
          via the <a href="https://cdn.rawgit.com/rabbitmq/rabbitmq-management/&version-server-tag;/priv/www/api/index.html"><code>api/queues/<i>vhost</i>/<i>qname</i></code></a>
          endpoint.
        </p>

        <table>
          <thead>
            <tr><td>Metric</td><td>JSON field name</td></tr>
          </thead>
          <tbody>
            <tr><td>Memory</td><td><code>memory</code></td></tr>
            <tr><td>Queued Messages</td><td><code>messages</code></td></tr>
            <tr><td>Un-acked Messages</td><td><code>messages_unacknowledged</code></td></tr>
            <tr><td>Messages Published</td><td><code>message_stats.publish</code></td></tr>
            <tr><td>Message Publish Rate</td><td><code>message_stats.publish_details.rate</code></td></tr>
            <tr><td>Messages Delivered</td><td><code>message_stats.deliver_get</code></td></tr>
            <tr><td>Message Delivery Rate</td><td><code>message_stats.deliver_get.rate</code></td></tr>
            <tr><td>Other Message Stats</td><td><code>message_stats.*</code> (see <a href="https://rawcdn.githack.com/rabbitmq/rabbitmq-management/master/priv/www/doc/stats.html">this document</a>)</td></tr>
          </tbody>
        </table>
      </doc:subsection>
    </doc:section>

    <doc:section name="monitoring-tools">
      <doc:heading>Monitoring Tools</doc:heading>
      <p>
        The following is an alphabetised list of third-party tools to collect RabbitMQ metrics. These
        tools have the capability to monitor the recommended system and RabbitMQ metrics.
      </p>
      <p>
        <table>
          <thead>
            <tr><td>Plugin</td><td>Online Resource(s)</td></tr>
          </thead>
          <tbody>
            <tr><td>AppDynamics</td><td><a href="https://www.appdynamics.com/community/exchange/extension/rabbitmq-monitoring-extension/">AppDynamics</a>, <a href="https://github.com/Appdynamics/rabbitmq-monitoring-extension">GitHub</a></td></tr>
            <tr><td><code>collectd</code></td><td><a href="https://github.com/signalfx/integrations/tree/master/collectd-rabbitmq">GitHub</a></td></tr>
            <tr><td>DataDog</td><td><a href="https://docs.datadoghq.com/integrations/rabbitmq/">DataDog RabbitMQ integration</a>, <a href="https://github.com/DataDog/integrations-core/tree/master/rabbitmq">GitHub</a></td></tr>
            <tr><td>Ganglia</td><td><a href="https://github.com/ganglia/gmond_python_modules/tree/master/rabbit">GitHub</a></td></tr>
            <tr><td>Graphite</td><td><a href="http://graphite.readthedocs.io/en/latest/tools.html">Tools that work with Graphite</a></td></tr>
            <tr><td>Munin</td><td><a href="http://munin-monitoring.org/">Munin docs</a>, <a href="https://github.com/ask/rabbitmq-munin">GitHub</a></td></tr>
            <tr><td>Nagios</td><td><a href="https://github.com/nagios-plugins-rabbitmq/nagios-plugins-rabbitmq">GitHub</a></td></tr>
            <tr><td>New Relic</td><td><a href="https://newrelic.com/plugins/vmware-29/95">NewRelic Plugins</a>, <a href="https://github.com/pivotalsoftware/newrelic_pivotal_agent">GitHub</a></td></tr>
            <tr><td>Prometheus</td><td><a href="/prometheus.html">Prometheus guide</a>, <a href="https://github.com/deadtrickster/prometheus_rabbitmq_exporter">GitHub</a></td></tr>
            <tr><td>Zabbix</td><td><a href="http://blog.thomasvandoren.com/monitoring-rabbitmq-queues-with-zabbix.html">Blog article</a></td></tr>
            <tr><td>Zenoss</td><td><a href="https://www.zenoss.com/product/zenpacks/rabbitmq">RabbitMQ ZenPack</a>, <a href="http://www.youtube.com/watch?v=CAak2ayFcV0">Instructional Video</a></td></tr>
          </tbody>
        </table>
      </p>
    </doc:section>

    <doc:section name="app-metrics">
      <doc:heading>Application-level Metrics</doc:heading>
      <p>
        A system that uses RabbitMQ, or any messaging-based system, is almost always distributed or can
        be treated as such. In such systems it is often not immediately obvious which component
        is problematic. Every single one of them, including applications, should be monitored and
        investigated.
      </p>
      <p>
       Some infrastructure-level and RabbitMQ metrics can demonstrate
       presence of an unusual system behaviour or issue but can't pin
       point the root cause. For example, it is easy to tell that a
       node is running out of disk space but not always easy to tell why.
       This is where application metrics come in: they can help identify
       a run-away publisher, a repeatedly failing consumer, a consumer that cannot
       keep up with the rate, even a downstream service that's experiencing a slowdown
       (e.g. a missing index in a database used by the consumers).
      </p>
      <p>
        Some client libraries (e.g. RabbitMQ Java client) and frameworks (e.g. Spring AMQP)
        provide means of registering metrics collectors or collect metrics out of the box.
      </p>
    </doc:section>

    <doc:section name="log-collection">
      <doc:heading>Log Aggregation</doc:heading>
      <p>
        While not technically a metric, one more piece of information can be very useful
        in troubleshooting a multi-service distributed system: logs. Consider collecting logs
        from all RabbitMQ nodes as well as all applications (if possible). Like metrics,
        logs can provide important clues that will help identify the root cause.
      </p>
    </doc:section>
  </body>
</html>
