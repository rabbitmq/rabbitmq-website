<?xml-stylesheet type="text/xml" href="page.xsl"?>
<!DOCTYPE html PUBLIC "bug in xslt processor requires fake doctype" 
"otherwise css isn't included" [
<!ENTITY % entities SYSTEM "rabbit.ent" >
%entities;
]>
<html xmlns:doc="http://www.rabbitmq.com/namespaces/ad-hoc/doc">
  <head>
    <title>RabbitMQ - Frequently Asked Questions</title>
  </head>
  <body>
    <doc:div>
      <h2>Frequently Asked Questions</h2>

      <p class="intro">
 See also these other sources of information:
<ul class="plain">
<li>an <a href="/how.html">Get Started</a> page which includes links to presentations, blog posts and community links.</li>
<li>our standard <a href="/documentation.html">documentation</a></li>
</ul>
</p>

<p>
	If you have a question not answered here,
	please <a href="http://lists.rabbitmq.com">join our mailing list</a> or
	alternatively, contact us directly at <a href="mailto:info@rabbitmq.com">info@rabbitmq.com</a>.
</p>
   

      <doc:faqtoc class="compact"/>

      <doc:section name="background">
	<doc:heading>Background</doc:heading>
	
	<doc:faq name="what-is-messaging">
	  <doc:heading>What is messaging?</doc:heading>
	  <doc:a>
	    <p>
	    Messaging describes the sending and receiving of data (in the form of messages) between systems. 
	    Messages are exchanged between programs or applications, similar to the way people communicate 
	    by email but with guarantees on delivery, speed, security and the absence of spam.
	    </p>
	    <p>
	    A messaging infrastructure (a.k.a. message-oriented middleware, a.k.a. enterprise service bus) 
	    makes it easier for developers to create complex applications by decoupling the individual program 
	    components. Rather than communicating directly, the messaging infrastructure facilitates the 
	    exchange of data between components. The components need know nothing about each other’s status,
	    availability or implementation, which allows them to be distributed over heterogeneous platforms 
	    and turned off and on as required.
	    </p>
	    <p>
	    In adopting this architecture, the developer is insulated from the details of the various operating 
	    systems and network interfaces involved and the interoperability, scalability and flexibility of the 
	    application are improved.
	    </p>
	    <p>
	    Please see this presentation on <a href="http://blog.pasker.net/2008/06/16/you-might-need-messaging-if/">Why you might need messaging</a>
	    for a general introduction or <a href="http://en.wikipedia.org/wiki/Message_Oriented_Middleware">this page on Wikipedia</a> 
	    for more information.
	    </p>
	  </doc:a>
	</doc:faq>
	
	<doc:faq name="what-is-amqp">
	  <doc:heading>What is AMQP?</doc:heading>
	  <doc:a>
	    <p>
	      <a href="specification.html">AMQP</a> is a standard
	      wire-level protocol and semantic framework for high
	      performance enterprise messaging.
	    </p>
	    <p>
	      From the AMQP website:
	    </p>
	    <blockquote>
	      <p>
		AMQP is an Open Standard for Messaging Middleware.
	      </p>
	      <p>
		By complying to the AMQP standard, middleware products
		written for different platforms and in different
		languages can send messages to one another. AMQP
		addresses the problem of transporting value-bearing
		messages across and between organisations in a timely
		manner.
	      </p>
	      <p>
		AMQP enables complete interoperability for messaging
		middleware; both the networking protocol and the
		semantics of broker services are defined in AMQP.
	      </p>
	    </blockquote>
	    <p>
	      For more information on what AMQP is, please see the <a
	      href="https://jira.amqp.org/confluence/display/AMQP/About+AMQP">AMQP
	      Working Group's overview page</a>.
	    </p>
	  </doc:a>
	</doc:faq>

	<doc:faq name="why-amqp">
	  <doc:heading>Why use AMQP?</doc:heading>
	  <doc:a>
	    <p>
	      AMQP is specifically designed with modern messaging
	      needs in mind, including the reduction of change and
	      maintenance costs through separation of integration
	      concerns, removal of silo dependency, and freedom from
	      language and platform lock in, without compromise on
	      user experience, security, scalability and consistently
	      excellent performance.
	    </p>
	    <p>
	      For more details please see <a
	      href="https://jira.amqp.org/confluence/display/AMQP/About+AMQP">this
	      page</a>.
	    </p>
	  </doc:a>
	</doc:faq>

	<doc:faq name="why-rabbitmq">
	  <doc:heading>Why use RabbitMQ?</doc:heading>
	  <doc:a>
	    <p>
	      RabbitMQ enables developers of messaging solutions to
	      take advantage of not just AMQP but also one of the most
	      proven systems on the planet.  The Open Telecom Platform
	      (OTP) is used by multiple telecommunications companies
	      to manage switching exchanges for voice calls, VoIP and
	      now video.  These systems are designed to never go down
	      and to handle truly vast user loads.  And because the
	      systems cannot be taken offline, they have to be very
	      flexible, for instance it must be possible to 'hot
	      deploy' features and fixes on the fly whilst managing a
	      consistent user SLA.
	    </p>
	    <p>
	      Instead of creating a new messaging infrastructure, the
	      RabbitMQ team selected the best one for the need, and
	      built an AMQP layer on top.  This combines the
	      robustness and scalability of a proven platform with the
	      flexibility of AMQP's messaging model.
	    </p>
	  </doc:a>
	</doc:faq>

	<doc:faq name="what-is-otp">
	  <doc:heading>What is the Open Telecom Platform (OTP)?</doc:heading>
	  <doc:a>
	    <p>
	      The <a href="http://www.erlang.se/">Open Telecom
	      Platform</a> (OTP) is a battle-tested library of
	      management, monitoring, and support code for
	      constructing extremely high-performance, reliable,
	      scalable, available (nine nines!) distributed network
	      applications. It is written in <a
	      href="http://www.erlang.org/">Erlang</a>.
	    </p>
	    <p>
	      For good general introductions to both technological and
	      business reasons supporting the use of Erlang and OTP,
	      we recommend the following:
	      <ul>
		<li>
		  An <a
		  href="http://www.ddj.com/architect/201001928"> 
      interview with Joe Armstrong</a>, Erlang and OTP's Chief Software Architect.
		</li>
		<li>
		  A discussion of <a
		  href="http://www.algorithm.com.au/talks/concurrency-erlang/">concurrency
		  and Erlang</a>, with examples from general Erlang
		  and OO programming, plus highlights from the online
		  multiplayer game industry.
		</li>
		<li>
		  An <a href="resources/armstrong.pdf">introduction to
		  Erlang</a> with motivating examples followed by
		  business proof-points.
		</li>
		<li>
		  A <a
		  href="resources/Carrier_Class_Telephony_Over_IP.pdf">white
		  paper</a> from Ericsson and Cisco (see particularly
		  page 15), discussing Ericsson's Engine Integral
		  softswitch solution, which is implemented using OTP
		  on Erlang.
		</li>
                <li>
                  A <a
                  href="http://www.erlang.se/euc/06/proceedings/1600Nystrom.ppt">case
                  study</a> by Motorola comparing the use of C++ and
                  Erlang for telecoms software.
                </li>
	      </ul>
	    </p>
	    <p>
	      For further details on the rationale for choosing
	      Erlang, please see the FAQ entries on <a
	      href="#clustering-design">clustering technology</a> and
	      <a href="#management-monitoring-control">management
	      interfaces</a>. Finally, we've prepared a comprehensive
	      assessment of Erlang's advantages at <a
	      href="erlang.html">this page</a>.
	    </p>
	  </doc:a>
	</doc:faq>

	<doc:faq name="scenarios">
	  <doc:heading>What messaging scenarios are supported by AMQP and RabbitMQ?</doc:heading>
	  <doc:a>
	    <p>
	      AMQP is a very general system that can be configured to
	      cover a great variety of messaging middleware
	      use-cases. For example:
	    </p>
	    <p>
	      <ul>
		<li>
		  <b>Point-to-point communication</b>
		  <p>
		    One of the simplest and most common scenarios is
		    for a message producer to transmit a message
		    addressed to a particular message consumer. AMQP
		    covers this scenario by allowing queues to be
		    named and to be bound to a "direct" exchange,
		    which routes messages to queues by name.
		  </p>
		</li>
		<li>
		  <b>One-to-many broadcasting (including multicast)</b>
		  <p>
		    In this scenario, the broadcasters publish
		    messages to an AMQP "fanout" exchange, and
		    subscribers create and subscribe to their own
		    private AMQP queues, which forward published
		    messages on to them, with one copy per queue.
		  </p>
		  <p>
		    Multicast is addressed at the broker
		    implementation level. AMQP clients need not be
		    made aware of transport-level optimisations such
		    as multicast: broker clusters are free to use
		    whatever such low-level optimisations are
		    available from configuration to configuration.
		  </p>
		  <p>
		    Multiple optimisations are possible, since AMQP
		    separates routing logic (exchanges and bindings)
		    from message queueing (queues). Multicast relates
		    only to routing from message publishers to message
		    queues, and as a routing optimisation can be
		    completely physically decoupled from AMQP's
		    logical semantics. Further optimisations include
		    physical separation of exchange from queue or even
		    colocation of queue with a consumer application.
		  </p>
		</li>
		<li>
		  <b>Transactional publication and acknowledgement</b>
		  <p>
		    AMQP supports transactional publication, where an
		    AMQP channel is opened, transactional mode is
		    selected, messages are published and acknowledged,
		    and the transaction is committed. The system
		    guarantees atomicity and durability properties for
		    transactional message activity.
		  </p>
		</li>
		<li>
		  <b>High-speed transient message flows</b>
		  <p>
		    Messages are individually flagged as transient or
		    persistent in AMQP at the time of publication. By
		    sending messages outside the transactional part of
		    the protocol, in non-persistent mode, an
		    application can achieve very high throughput and
		    low latency.
		  </p>
		</li>
		<li>
		  <b>Reliable persistent message delivery</b>
		  <p>
		    Messages that are published in persistent mode are
		    logged to disk for durability. If the server is
		    restarted, the system ensures that received
		    persistent messages are not lost. The
		    transactional part of the protocol provides the
		    final piece of the puzzle, by allowing the server
		    to communicate its definite receipt of a set of
		    published messages.
		  </p>
		</li>
		<li>
		  <b>Store-and-forward</b>
		  <p>
		    Store-and-forward is implemented by delivering
		    messages marked as "persistent" to AMQP's durable
		    queues. Published, persistent messages delivered
		    to durable queues are stored on disk until a
		    consumer retrieves and deletes them.
		  </p>
		</li>
		<li>
		  <b>Wide area messaging</b>
		  <p>
		    Because routing logic is decoupled from message
		    delivery, RabbitMQ is able to support extended
		    broker clustering across WANs. Some of the
		    approaches include AJAX-style access to AMQP
		    resources, and spanning-tree pseudo-multicast
		    implemented internally to a RabbitMQ cluster.
		  </p>
		</li>
		<li>
		  <b>File streaming</b>
		  <p>
		    The AMQP protocol, version 0-8, supports file
		    streaming by way of the <code>file</code> content
		    class. Very large files are transferred to a
		    temporary area on the broker before being routed
		    to queues for download by consumers.
		  </p>
		</li>
	      </ul>
	    </p>
	  </doc:a>
	</doc:faq>

      </doc:section>

      <doc:section name="managing-concepts-exchanges">
	<doc:heading>Messaging Concepts: Exchanges</doc:heading>
	
	<doc:faq name="fanout-exchange">
	  <doc:heading>What is a fanout exchange?</doc:heading>
	  <doc:a>
	    <p>
	    A fanout exchange is the simplest exchange type, representing a 1:N message delivery
	    pattern. No routing keys are involved – you simply bind a queue to the exchange and
	    messages sent to that exchange get delivered to <strong>all</strong> the bound queues.	
	    </p>
	  </doc:a>
	</doc:faq>
	
	<doc:faq name="direct-exchange">
	  <doc:heading>What is a direct exchange?</doc:heading>
	  <doc:a>
	    <p>
	    A direct exchange is a 1:1 form of communication where a routing key directs how a broker
	    routes the message from the producer to the consumer. This is a straight match. If a queue
	    binds to an exchange requesting messages with the routing key "lady", only messages labelled
	    "lady" get delivered to that queue (not "lady.bird" or "lady.macbeth").	
	    </p>
	  </doc:a>
	</doc:faq>
	
	<doc:faq name="topic-exchange">
	  <doc:heading>What is a topic exchange?</doc:heading>
	  <doc:a>
	    <p>
	    Here, the broker matches the routing key against a pattern to determine how to deliver the
	    message. Instead of binding a queue to an exchange with a simple string, the queue is bound
	    with a pattern. In the pattern, the symbol # matches one or more words and the symbol *
	    matches any single word. Typical bindings might be "uk.#" for all items in the uk, "#.weather"
	    for all weather items, or "uk.weather" for all uk weather items.	
	    </p>
	  </doc:a>
	</doc:faq>	
	
	<doc:faq name="exchange-client-or-server">
	  <doc:heading>Do I create the exchanges on the server or is it all done with my client-side library?</doc:heading>
	  <doc:a>
	    <p>
	    You would use some client to issue exchange.declare, which creates the exchange on the
	    server when the server receives the command. You can do the exchange.declare at any time
	    before you need to use the exchange.	
	    </p>
	  </doc:a>
	</doc:faq>	
	
	<doc:faq name="exchange-why-client">
	  <doc:heading>I don't understand why the exchanges are created at the client. Doesn't it make sense to create them on the server?</doc:heading>
	  <doc:a>
	    <p>
	    The semantics of exchange.declare are that if the exchange does not already exist on the server,
	    then create a new exchange. Otherwise reuse an existing exchange.	
	    </p>
	  </doc:a>
	</doc:faq>
	
	<doc:faq name="organize-exchanges">
	  <doc:heading>How do I organize my exchanges in the case where the message recipients represent a hierarchy?</doc:heading>
	  <doc:a>
	    <p>
	    You may want to read the part in the spec about how the topic exchanges work. Using
	    the example of nations which include sectors which include states which include regions
	    which include counties, you could use topic exchange with 'nz.northisland.wellington.arovalley.arostreet.
	    54' and the bind with a pattern of nz.# or nz.southisland.#

	    </p>
	  </doc:a>
	</doc:faq>
	
	<doc:faq name="exchanges-routing-key-bind-pattern-hash">
	  <doc:heading>Is a topic exchange with routing-key binding pattern "#" essentially a fanout?</doc:heading>
	  <doc:a>
	    <p>
	    Yes.
	    </p>
	  </doc:a>
	</doc:faq>
	
	<doc:faq name="fanout-direct-topic-specialisations">
	  <doc:heading>Hey, fanout and direct look like simple specialisations of topic. Am I right?</doc:heading>
	  <doc:a>
	    <p>
	    Yep.
	    </p>
	    <p>
	    Direct exchanges can be simulated by using topic exchanges without wildcards, and fanout
	    exchanges can be simulated by binding to topic exchanges with a full wildcard pattern.
	    </p>
	    <p>
	    The different kinds of exchange exist mainly for clarity's sake: it's easier for an observer
	    looking at a system to see the intent behind the way it's configured. Secondarily, it opens up
	    opportunities for optimising the less-general kinds of exchange.
	    </p>
	  </doc:a>
	</doc:faq>
	
	<doc:faq name="exchange-lifespan">
	  <doc:heading>When I create an exchange does it stay created or does the exchange disappear 
	  anytime the client disconnects?</doc:heading>
	  <doc:a>
	    <p>
	    Whether they disappear in time or not depends on the options that you set when you declare
	    an exchange. One option is durability, which means an exchange will survive a server restart.
	    Autodelete is another option that indicates that the server should remove an exchange when
	    all queues have stopped using it.
	    </p>
	  </doc:a>
	</doc:faq>
	
	<doc:faq name="which-entity-should-declare-exchanges">
	  <doc:heading>I'm interested in creating an exchange. Which entity should declare the exchange,
	  the publisher or subscriber?</doc:heading>
	  <doc:a>
	    <p>
	    Not wanting to be overly theoretical, but the AMQP working group is now moving to a more
	    formal definition of declarations that mean that they have the same semantics as an assertion.
	    </p>
	    <p>
	    So by saying declare queue q or declare exchange x, you are effectively saying "I assert the
	    existence of object o, if it does not exist, make it so".
	    </p>
	    <p>
	    Publishers need to write to somewhere.
	    </p>
	    <p>
	    Consumers need to have queues bound to something.
	    </p>
	    <p>
	    So both sides are only interested in the mere existence of the thing they need to do their job,
	    not whether they or some other guy originally initiated that object's creation.
	    </p>
	  </doc:a>
	</doc:faq>
	
	<doc:faq name="publisher-and-consumer-declare-exchanges">
	  <doc:heading>Does it makes sense for both the publisher and subscriber to each declare the exchange?</doc:heading>
	  <doc:a>
	    <p>
	    Semantically yes. But don't be too dogmatic about it in every scenario, if your application
	    knows for sure that a particular queue or exchange definitely does exist, it can save a lookup
	    for the existence of that object. Just an efficiency consideration. But don't optimize
	    prematurely :-)
	    </p>
	  </doc:a>
	</doc:faq>
	
      </doc:section>
      

      <doc:section name="Binding-and-Routing">
	<doc:heading>Messaging Concepts: Binding and Routing</doc:heading>

	<doc:faq name="what-are-bindings">
	  <doc:heading>What are bindings?</doc:heading>
	  <doc:a>
	    <p>
	    When you publish a message, you send a "routing key" along with it, that's used by the
	    exchange when it decides which queues to forward a copy of the message on to. The links
	    between exchanges and queues are created through binding, with a "binding pattern" that is
	    used by the exchange when comparing against routing keys.
	    </p>
	  </doc:a>
	</doc:faq>

	<doc:faq name="wildcards-in-topic-exchanges">
	  <doc:heading>How do the wildcards work when binding to topic exchanges?</doc:heading>
	  <doc:a>
	    <p>
	    Routing keys (and so binding patterns) used with topic exchanges are
	    dot.separated.strings.like.this.
	    </p>
	    <p>
	    Use "*" to match a single segment in the routing key: foo.*.zot will match foo.bar.zot, and
	    foo.quux.zot, but not foo.bar.quux.zot.
	    </p>
	    <p>
	    Use "#" to match zero or more segments in the routing key: foo.#.zot will match all three of
	    foo.bar.zot, foo.quux.zot, and foo.bar.quux.zot, as well as foo.zot.
	    </p>
	  </doc:a>
	</doc:faq>

	<doc:faq name="pattern-matching">
	  <doc:heading>I've declared a queue and then bound it to the exchange "x" on topic
	  "canada.politics". Other queues that bind on "canada.politics", publish messages
	  and it works great. If they bind to lets say "canada.sports" it also works as expected
	  in routing the messages. But if i publish to "canada.*" those clients in
	  canada.politics and canada.sports do not receive the messages. Is that expected, or
	  something wrong with the code?
	  </doc:heading>
	  <doc:a>
	    <p>
	    You've got the pattern matching around the wrong way. The routing key must be absolute
	    whilst the binding key can contain a wildcard. So "canada.*" is an opaque routing key. So to
	    fix this, use "canada.*" as the binding key instead of "canada.sports" or "canada.politics".
	    </p>
	  </doc:a>
	</doc:faq>

	<doc:faq name="pattern-matching-with-separate-bindings">
	  <doc:heading>But what if I'm interested in "canada.politics" and "canada.sports", but not
	  "canada.entertainment"?</doc:heading>
	  <doc:a>
	    <p>
	    Then create a separate binding for each thing that you are interested in.
	    </p>
	  </doc:a>
	</doc:faq>

	<doc:faq name="declare-multiple-routing-keys-for-single-queue">
	  <doc:heading>Is it possible to declare multiple routing keys for a single queue in a direct
	  exchange?</doc:heading>
	  <doc:a>
	    <p>
	    Yes. See the previous FAQ.
	    </p>
	  </doc:a>
	</doc:faq>		

	<doc:faq name="direct-exchanges-sending-to-multiple-queues">
	  <doc:heading>What happens if a queue is bound to a direct exchange with more than one routing key?</doc:heading>
	  <doc:a>
	    <p>
	  This is a pub-sub scenario. The direct exchange behaves a little bit like a fanout
	  exchange and the message is delivered to all queues that have a matching key.
	    </p>
	  </doc:a>
	</doc:faq>		

	<doc:faq name="durable-queues-and-durable-exchanges">
	  <doc:heading>Why can durable queues only bind to durable exchanges?</doc:heading>
	  <doc:a>
	    <p>
	    This is just an artifact of the two tier model in AMQP. You either want to be 100% durable in
	    all tiers, or you don't.
	    </p>
	  </doc:a>
	</doc:faq>		

	<doc:faq name="mandatory-flat-routing">
	  <doc:heading>Can you explain how the <strong>mandatory</strong> flag affects message routing?</doc:heading>
	  <doc:a>
	    <p>
	  From the <a href="http://www.amqp.org/confluence/display/AMQP/AMQP+Specification">AMQP specification</a>:
	  "This flag tells the server how to react if a message cannot be routed to a
	  queue". Specifically, if mandatory is set and after running the bindings the
	  message was placed on zero queues then the message is returned to the sender
	  (with a basic.return). If manadatory had not been set under the same
	  circumstances the server would silently drop the message."
	    </p>
	  </doc:a>
	</doc:faq>		

	<doc:faq name="immediate-flat-routing">
	  <doc:heading>Can you explain how the <strong>immediate</strong> flag affects message routing?</doc:heading>
	  <doc:a>
	    <p>
	  From the <a href="http://www.amqp.org/confluence/display/AMQP/AMQP+Specification">AMQP specification</a>:	 
	  "This flag tells the server how to react if the message cannot be routed to
	  a queue consumer immediately". The languange here is a little ambiguous but, to
	  the best of our understanding (and this is what RabbitMQ implements), we take
	  it to mean the following.
	    </p>
	    <p>
	  For a message published with immediate set, if a matching queue has ready consumers 
	  then one of them will have the message routed to it. If the lucky consumer crashes 
	  before ack'ing receipt the message will be requeued and/or delivered to other 
	  consumers on that queue (if there's no crash the messaged is ack'ed and it's all 
	  done as per normal). If, however, a matching queue has zero ready consumers the message 
	  will not be enqueued for subsequent redelivery on from that queue. Only if all of the 
	  matching queues have no ready consumers that the message is returned to the sender 
	  (via basic.return).
	    </p>
	    <p>
	  FWIW, a consumer in this instance is a channel that has used basic.consume to
	  subscribe to a queue (basic.get doesn't qualify a channel as a
	  consumer for these purposes as it is 'instananeous')."
	    </p>
	  </doc:a>
	</doc:faq>	
</doc:section>

<doc:section name="features">
	<doc:heading>Messaging Concepts: General</doc:heading>

  <doc:faq name="message-ordering">
    <doc:heading>I have read that RabbitMQ preserves the order of messages in queues. Is this correct?</doc:heading>  
    <doc:a>
      <p>For the most part, yes. Say a publisher publishes messages M1, M2, M3 and M4 (in that order) on the same channel
      and with the same routing information. If these messages are routed to a queue then they will end up in the same order that
      they were published. Consuming on the queue will yield M1, M2, M3 and then M4.</p>
      <p>However, the order is only guaranteed in the absence of requeuing. A message will be implicitly requeued if a consumer
      closes the channel before ack'ing a message. For example, if a consumer receives M1, fails to ack and closes the channel then
      the next consumer will receive messages in the order M2, M3, M4, M1. Messages can also be explicitly requeued if the consumer
      calls <code>basic.recover{requeue=true}</code>. The FAQ on <a href="#at-least-once-delivery">at least once delivery</a> talks
      about this in some more detail.
      </p>
      <p>Section 4.7 of <a href="http://www.amqp.org/confluence/download/attachments/720900/amqp0-9-1.pdf?version=1&amp;modificationDate=1227526523000">the AMQP 0-9-1 specification</a>
      explains the conditions under which ordering is guaranteed.</p>
    </doc:a>
  </doc:faq>

</doc:section>

      <doc:section name="features">
	<doc:heading>RabbitMQ Features</doc:heading>

	<doc:faq name="feature-transactional">
	  <doc:heading>Is RabbitMQ transactional?</doc:heading>
	  <doc:a>
	    <p>
	      Yes. RabbitMQ implements AMQP's "TX" message class, which
	      provides atomicity and durability properties to those
	      clients that request them.
	    </p>
	  </doc:a>
	</doc:faq>

	<doc:faq name="feature-reliable">
	  <doc:heading>Is RabbitMQ reliable and highly-available?</doc:heading>
	  <doc:a>
	    <p>
	      Yes. RabbitMQ is built atop the industry-leading <a
	      href="#what-is-otp">OTP</a> Erlang libraries, which
	      provides a solid foundation for building reliable
	      software. The underlying system supporting the Rabbit
	      codebase has been used by Ericsson to achieve <i>nine
	      nines</i> (99.9999999%) of availability.
	    </p>
	  </doc:a>
	</doc:faq>

	<doc:faq name="feature-clustering-failover">
	  <doc:heading>Does RabbitMQ support clustering, and high-availability through live failover?</doc:heading>
	  <doc:a>
	    <p>
	      Yes. RabbitMQ brokers can be made up of an arbitrary
	      number of nodes, each of which is available for AMQP
	      clients to connect to and interact with. RabbitMQ's
	      routing tables are shared across the entire cluster, and
	      delivery of messages published at one node to a queue
	      residing at another node is seamless. For details see
	      the <a href="clustering.html">clustering guide</a> and
	      the <a href="pacemaker.html">high availability</a>
	      guide.
	    </p>
	  </doc:a>
	</doc:faq>

	<doc:faq name="smp-support">
	  <doc:heading>Will RabbitMQ use SMP, when it's available?</doc:heading>
	  <doc:a>
	    <p>
	      Yes. Erlang supports both single-node SMP configurations
	      and configurations with multiple Erlang nodes running in
	      a cluster within a single host.
	    </p>
	  </doc:a>
	</doc:faq>

	<doc:faq name="support-store-and-forward">
	  <doc:heading>Does RabbitMQ support store-and-forward?</doc:heading>
	  <doc:a>
	    <p>
	      Yes, RabbitMQ, and AMQP in general, supports
	      store-and-forward-style exchanges and queues.
	    </p>
	  </doc:a>
	</doc:faq>

	<doc:faq name="SMSstore-forward">
	  <doc:heading>Do you think RabbitMQ, as a core module, could handle real time traffic of
something like an SMSC (SMS foreward&amp;store)?</doc:heading>
	  <doc:a>
	    <p>
Absolutely. Some large telcos currently deploy Erlang/OTP-based systems
    in their SMSC infrastructure. At present these systems are not based on
    AMQP/RabbitMQ, but there is no reason why they couldn't be.

	    </p>
	  </doc:a>
	</doc:faq>

	<doc:faq name="webframework-support">
	   <doc:heading>Can I create RabbitMQ applications using web frameworks (e.g. Spring, or Ruby-On-Rails)?
	  </doc:heading>
	  <doc:a>
	    <p>
	      Yes. To begin with, Spring has <a href="#rabbit-spring-support">support for AMQP</a> in Java
	      through the <a href="http://www.springsource.org/spring-amqp">Spring AMQP project</a>. The
	      RabbitMQ Java client is simply a POJO library so will work with other POJO-based systems, such as <a href="http://mulesource.org">Mule</a>. If you
	      specifically wish to use JavaEE EJBs as message  accessors, use a stateful session bean.
	    </p>
	    <p>
	      For frameworks in other languages, such as Ruby or
	      in-browser Javascript, we plan on providing both RESTful
	      HTTP access to AMQP features as well as AJAX- and
	      web-services-style interfaces, allowing rapid
	      development of web applications that take advantage of
	      AMQP messaging.
	    </p>
	  </doc:a>
	</doc:faq>


	<doc:faq name="message-delivered">
	   <doc:heading>At what point is a message delivered, from the sender's perspective?</doc:heading>
	  <doc:a>
	    <p>
	      Publication is an asynchronous activity - in other words, a message
	      is "published" as soon it has left the client's TCP stack. The client
	      has no knowledge of to whom the message is delivered. If you want some
	      guarantees, you can use the mandatory and immediate flags on
	      basic.publish, and you can also use transactional mode. In
	      transactional mode, publishes are batched on the broker, until
	      you issue a tx.commit. When you get the tx.commit-ok message
	      back (i.e. commit is synchronous), you know the broker really has
	      received the messages.
	    </p>
	  </doc:a>
	</doc:faq>

	<doc:faq name="at-least-once-delivery">
	   <doc:heading>Can you explain the cases where a message might be delivered to a consumer more than once? </doc:heading>
	  <doc:a>
	    <p>
	      If a message is delivered to a consumer, and that consumer then
	      dies (or closes the channel which has the subscription to the
	      queue, or closes the connection itself) without acking the
	      message, then RabbitMQ will reinject the message into the queue. If
	      that same consumer then reconnects and creates a new subscription
	      to the same queue, it's possible it'll receive the same message
	      again. This is 'at least once' delivery and is very deliberate
	      design to ensure that messages are not lost in transit.
	    </p>
	    <p>
	      The consumer can also call basic.recover which tells rabbit to
	      resend all the messages sent to the consumer for which rabbit has
	      not received an ack for. This basically amounts to the consumer
	      saying "I know you sent me some messages, but I've forgotten what
	      they are. Could you resend them all again?".
	    </p>
	  </doc:a>
	</doc:faq>
	
	
      </doc:section>

      <doc:section name="architecture">
	<doc:heading>RabbitMQ Architecture</doc:heading>

	<doc:faq name="authentication-authorization">
	  <doc:heading>How is authentication and authorization supported in RabbitMQ?</doc:heading>
	  <doc:a>
	    <p>
	      AMQP uses <a
	      href="http://tools.ietf.org/html/rfc4422">SASL</a> (see
	      also <a
	      href="http://en.wikipedia.org/wiki/Simple_Authentication_and_Security_Layer">Wikipedia
	      on SASL</a>) for authentication of AMQP clients. Our
	      current support for SASL is limited to the PLAIN
	      authentication mechanism.
	    </p>
	    <p>
	      Authorization is implemented in RabbitMQ using a
	      distributed database table mapping users to virtual
	      hosts.
	    </p>
	    <p>
	      Message authentication, for instance using <a
	      href="http://en.wikipedia.org/wiki/Message_authentication_code">cryptographic
	      message authentication codes</a>, is not defined by the
	      AMQP specification, but as for encryption, could be very
	      easily implemented within the RabbitMQ client library.
	    </p>
	  </doc:a>
	</doc:faq>

	<doc:faq name="rabbit-platforms">
	  <doc:heading>What platforms will RabbitMQ run on?</doc:heading>
	  <doc:a>
	    <p>
	      RabbitMQ is developed on Debian Linux and Mac OS X. As
	      the server component is written in Erlang, and the
	      client component in Java, it is platform-neutral. Erlang
	      runs on the following platforms (taken from <a
	      href="http://www.erlang.org/faq/faq.html#AEN903">Erlang's
	      FAQ</a>):
	    </p>
	    <p>
	      <ul class="compact">
		<li>Solaris (including 64 bit)</li>
		<li>BSD</li>
		<li>Linux</li>
		<li>OSX</li>
		<li>TRU64</li>
		<li>Vista/Windows 7</li>
		<li>Windows NT/2000/2003/XP</li>
		<li>Windows 95, 98</li>
		<li>VxWorks</li>
	      </ul>
	    </p>
	  </doc:a>
	</doc:faq>

	<doc:faq name="shared-session-clustering">
	  <doc:heading>What is shared session clustering?</doc:heading>
	  <doc:a>
	    <p>
	      For those familiar with typical tiered
	      session/application architectures such as JavaEE, it
	      might help to think of the AMQP exchanges as
	      corresponding to a logical session tier, and AMQP queues
	      as corresponding to a logical application tier. From
	      this point of view, RabbitMQ's routing tables can be seen
	      as clustered shared session state. RabbitMQ uses the OTP
	      distributed database, Mnesia, to reliably and
	      persistently replicate session state across all nodes in
	      a cluster.
	    </p>
	  </doc:a>
	</doc:faq>

	<doc:faq name="clustering-design">
	  <doc:heading>How does clustering work?</doc:heading>
	  <doc:a>
	    <p>
	      RabbitMQ's current clustering mechanisms are built around
	      Erlang's native support for reliable distributed
	      programming. This is a deeply sophisticated framework,
	      implemented at the language and virtual-machine level.
	    </p>
	    <p>
	      Some of the unique points about Erlang's networking and
	      distribution model are:
	      <ul>
		<li>
		  it scales to hundreds of thousands of parallel
		  processes ("green threads") within a single virtual
		  machine, bounded only by available memory;
		</li>
		<li>
		  the failure model for local inter-process
		  communication (IPC) is the same as that for
		  distributed IPC, making the transition from
		  non-distributed to distributed code very smooth;
		</li>
		<li>
		  binary pattern-matching constructs within the
		  language ensure straightforward and efficient
		  translation between wire-level encodings and
		  internal Erlang data structures;
		</li>
		<li>
		  finally, the OTP libraries shipped with the Erlang
		  distribution include the notion of a
		  supervisor/worker relationship, where supervisor
		  processes monitor and restart worker processes under
		  their control, making management of the entire
		  process hierarchy within a server deterministic and
		  automatic.
		</li>
	      </ul>
	    </p>
	    <p>
	      Within an Erlang node cluster, Erlang's native
	      high-speed messaging is used to provide an efficient way
	      of distributing work across the cluster. Individual AMQP
	      clients connect to machines within the cluster, and
	      Erlang's distributed routing database routes AMQP
	      messages to the appropriate endpoints.
	    </p>
	    <p>
	      For more detail on Erlang's benefits in an AMQP setting,
	      please see <a href="erlang.html">this page</a>.
	    </p>
	  </doc:a>
	</doc:faq>

	<doc:faq name="addressing-in-amqp">
	  <doc:heading>How does addressing work in AMQP?</doc:heading>
	  <doc:a>
	    <p>
	      Like other messaging systems, AMQP and RabbitMQ provide
	      internal addressing mechanisms based on notions such as
	      routing keys, exchange addresses and queue
	      names.
	    </p>
	    <p>
	      These are managed on a per-virtual-host basis. Please
	      see the AMQP specification for details of the scoping of
	      the various names in the network. We are actively
	      investigating interoperation with other addressing
	      schemes and systems.
	    </p>
	  </doc:a>
	</doc:faq>
	
		<doc:faq name="scale-balance">
	  <doc:heading>How is RabbitMQ scaled and the load balance handled?</doc:heading>
	  <doc:a>
	    <p>
	     At the core we are relying on Erlang/OTP to distribute one logical AMQP
    broker across several physical nodes, with the necessary broker state
    being maintained in an instance of OTP's distributed database Mnesia.
    There are certain aspects of the AMQP spec that are currently undergoing
    revision that impact this area, so watch out for associated new features
    and documentation in future releases of RabbitMQ.

	    </p>
	  </doc:a>
	</doc:faq>
	
    <doc:faq name="server-api">
	<doc:heading>Is there an API doc of the RabbitMQ server?</doc:heading>
	<doc:a>
	  <p>
	  No, the Rabbit server API is not designed for public
	  consumption. The AMQP specification is the public API
	  specification for RabbitMQ server.
	   </p>
	  <p>
	  We do, however, have API guides for
	  </p>
	  <ul>
	      <li>Java (<a href="api-guide.html">API guide proper</a> and 
	      <a href="&dir-current-javadoc;">javadoc</a>), and</li>
	      <li>.NET (<a href="releases/&dir-dotnet-client;/&nameVersion-dotnet-client;-user-guide.pdf">API guide proper (PDF)</a> and 
	      <a href="&dir-current-dotnet-apidoc;/index.html">javadoc-like</a>)</li>
	  </ul>    
	  <p>
	  Also, please refer to the extensive <a href="/documentation.html#server">server documentation</a> which may contain the answer to
	  your question.       
	  </p>
	</doc:a>
    </doc:faq>
	
      <doc:faq name="node-runs-out-of-memory">
	<doc:heading>What happens when a node runs out of message memory? Does the node fall over?</doc:heading>
	<doc:a>
	  <p>
	    Glad you asked. We've been working on a new persister since April (please
	    see <a href="http://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">the mailing list</a> or
	    <a href="http://www.lshift.net/blog/2009/12/07/rabbitmq-at-the-skills-matter-functional-programming-exchange">these slides</a> for more). 
	  </p>
	  <p>
	    The goal is to page messages to disk when necessary, politely
	    block producers when absolutely necessary, and never ever
	    crash. We should always be able to eventually accept a message.
	  </p>
	  <p>
	    Note that the current stable release (v1.7.0) (and all previous
	    releases) is not very good in this regard and can easily explode
	    due to holding too many messages in memory.
	  </p>
	</doc:a>
      </doc:faq>

     <doc:faq name="limitation-on-message-size">
	<doc:heading>What limitations are there on message size? For example, If I have
	    a box with 8GB of RAM will it be able to hold one 8GB message?</doc:heading>
	<doc:a>
	  <p>
	    The main limitation is installed memory on the server (or, more accurately,
	    the amount of per-process memory available on your platform).
	  </p>
	  <p>
	    However, it's not as simple as available RAM = maximum message size. This
	    would only be possible if there was zero copying of a message from when
	    it arrives at the machine until when it leaves. Its very likely that
	    it will be copied several times.
	  </p>
	  <p>
	    We would be surprised if it's possible to push messages into RabbitMQ that
	    are greater than 1/4 of the installed RAM. RabbitMQ tries to avoid using
	    swap wherever possible and uses a configurable parameter to set a <a href="http://www.rabbitmq.com/extensions.html#memsup">memory
	    threshold above which producers are throttled</a>.
	  </p>
	  <p>
	    Be aware that <a href="http://msdn.microsoft.com/en-us/library/aa366778%28VS.85%29.aspx#physical_memory_limits_windows_7">Windows 
	    imposes some "gotcha" constraints on per-process memory</a> that have 
	    caught some people out in the past.
	  </p>	
	 </doc:a>
      </doc:faq>
      
      <doc:faq name="new-persister-memory-limitations">
	<doc:heading>How does the new persister affect the memory limitations?</doc:heading>
	<doc:a>
	  <p>
	    The next major release of RabbitMQ will include the new persister that (amongst
	    other things) removes the current limitation that RabbitMQ holds all messages
	    in memory all the time.
	  </p>
	  <p>
	    The persister will allow RabbitMQ to operate in a "zero RAM
	    cost per message" mode where the volume of data that RabbitMQ can hold is
	    limited solely by disk space.
	  </p>
	  <p>
	    However, even with the new persister, the fact remains that not only
	    will the largest message need to fit in RAM (at some point) but it must
	    also be able to be copied a few times. The change is simply that the existence
	    of large messages in RAM does not preclude other large messages from
	    arriving.
	  </p>
	</doc:a>
      </doc:faq>

      <doc:faq name="enable-large-messages">
	<doc:heading>I heard that AMQP supports streaming for large messages. How do we enable this?</doc:heading>
	<doc:a>
	  <p>
	    AMQP 0-8 included mention of a "stream" transfer class. However, no one
	    implements it and it's gone in AMQP 0-9-1. It is the responsibility of
	    applications to chunk large messages if they need to.
	  </p>
	  <p>
	    There are some client libs for doing 'file chunking'. 
	    <a href="http://github.com/ezmobius/nanite/tree/master">Nanite</a>  is the one to look at if you are a Ruby developer.
	  </p>
	</doc:a>
      </doc:faq>
      
      <doc:faq name="sticky-queues">
	<doc:heading>Queues are sticky to the node upon which they are created. 
	Do you plan to change this in future versions?</doc:heading>
	<doc:a>
	  <p>
	    It is not scheduled for any particular future version. It's
	    likely it'll be addressed through some sort of active/active
	    high-availability setup, but in general this is a 
	    <span class="underline">very</span> hard thing to try and do.
	    Ultimately, the messages are going to have to exist on more 
	    than one node, and maybe written to disk on more than one 
	    node. This substantially complicates all sorts of semantics 
	    and guarantees of AMQP. Yes, we do plan to address this
	    but it's very much a long term goal.
	  </p>
	</doc:a>
      </doc:faq>
      
      </doc:section>

      <doc:section name="integration">
	<doc:heading>RabbitMQ Integration &amp; Interoperability</doc:heading>

	<doc:faq name="rabbit-client-support">
	  <doc:heading>What clients does RabbitMQ support?</doc:heading>
	  <doc:a>
	    <p>
	      We maintain <a href="/how.html#clients">a list of clients</a>, which is fairly complete.  If you don't
see one you want, please <a href="http://lists.rabbitmq.com/cgi-bin/mailman/listinfo">email our mailing list.</a>
	    </p>
	  </doc:a>
	</doc:faq>
  <doc:faq name="rabbit-spring-support">
    <doc:heading>What options are provided for integrating RabbitMQ with the Spring framework?</doc:heading>
    <doc:a>
      <p>The <a href="http://www.springsource.org/spring-amqp">Spring AMQP project</a> applies core Spring
      concepts to the development of AMQP-based messaging solutions. The project provides a set of "templates" as high-level
      abstractions for sending and receiving messages. Message-driven POJOs are also supported. The libraries facilitate
      management of AMQP resources while promoting the use of dependency injection and declarative configuration. In
      all of these cases, you will see similarities to the JMS support in the Spring Framework.
      The project consists of both Java and .NET versions.</p>
      </doc:a>
    </doc:faq>
	<doc:faq name="rabbit-webmessaging-support">
	  <doc:heading>What support does RabbitMQ provide for web messaging?</doc:heading>
	  <doc:a>
	    <p>
	      There are multiple ways for interacting with RabbitMQ in web messaging scenarios. For example, 
	      we provide broker plugins that expose a JSON/RPC endpoint from within the broker process. The 
	      community has contributed a set client libraries that allow AMQP communication for a variety of 
	      web platforms including actionscript and pubsubhubbub. A more complete list can be found under 
	      <a href="how.html#web-messaging">Web Messaging on the Get Started page</a>.
	    </p>
	  </doc:a>
	</doc:faq>
	
	<doc:faq name="AMQP-specs">
	  <doc:heading>Can you enlighten me about the differences between different versions of the AMQP specs?</doc:heading>
	  <doc:a>
	    <p>
	      The differences between 0-8, 0-9 and 0-91 are really small.  The 0-91
	      version of the spec, which we support in dev (pre-release branch of
	      our repo) has one major benefit: interoperability with OpenAMQ 0-91 and
	      Qpid 0-91 in the main areas of behaviour (though note that OpenAMQ
	      only partially implements AMQP). This is being tested now and you
	      can expect more ‘noise’ about this in Q1 2010 in the community.
	    </p>
	  </doc:a>
	</doc:faq>
  
	<doc:faq name="AMQP-0-8-0-91">
	  <doc:heading>So, what does AMQP 0-8 lack by comparison with 0-91?</doc:heading>
	  <doc:a>
	    <p>
	      There is definitely no critical feature that 0-8 lacks but 0-91 has the
	      merit of being shorter and tidying up lots of interoperability bugs. 0-9
	      has stuff in it that people did not like and this was removed in 0-91.
	    </p>
	  </doc:a>
	</doc:faq>
	
  
	<doc:faq name="AMQP-1-0-migration">
	  <doc:heading>What are your plans for migrating yourselves and your users to AMQP 1-0 when it is finalised?</doc:heading>
	  <doc:a>
	    <p>
	      The <a href="https://www.amqp.org/confluence/display/AMQP/AMQP1.0+SIG">AMQP 1-0 draft spec</a>
	      is still a work in progress and introduces some major changes from previous
	      versions. 
	    </p>
	    <p>
	      Our plan is to support 1-0 once it is finalised.  As a matter of
	      practicality we will offer a migration path, for example it will be possible
	      to simulate 0-8 and 0-91 in 1-0.  We do not expect 1-0 to be ready for
	      serious implementation in the near term, and are satisfied that we are
	      supporting the right versions with 0-8 and 0-91.
	    </p>
	  </doc:a>
	</doc:faq>
	
	<doc:faq name="connections-channels">
	  <doc:heading>Can you recommend the best way to work with connections and channels in my application?</doc:heading>
	  <doc:a>
	    <p>
	      In general, it is better to create a single connection and as many channels as you need
	      (rather than many connections with a single channel each).
	    </p>
	  </doc:a>
	</doc:faq>
	
      </doc:section>

      <doc:section name="howto">
	<doc:heading>How-To</doc:heading>
	
	<doc:faq name="erlang-crash-sos">
	  <doc:heading>Help me! I'm having problems when trying to install / run / configure
	    RabbitMQ. The console tells me that "Crash dump was written to: erl_crash.dump"
	    accompanied by lots of utterly incomprehensible Erlang. What should I do?</doc:heading>
	  <doc:a>
	    <p>
	    Don't panic! In the (unlikely) event that something goes wrong help is
	    available. If you can't make sense of the error yourself then your
	    first port of call should be our <a href="install.html#troubleshooting">troubleshooting guide</a>.
	    </p>
	  </doc:a>
	</doc:faq>
	
	<doc:faq name="last-message-on-topic">
	  <doc:heading>How can I ensure that a message can always reach a suitable queue even if the
	  RabbitMQ node which I’m sending to crashes?</doc:heading>
	  <doc:a>
	    <p>
	    At the risk of sounding pedantic, you could wait for the dead node to recover
	    from disk.  In other words, RabbitMQ provides "eventual delivery" out of the
	    box.  If you want to persist more reliably than with a single disk then use a 
	    RAID or a SAN.
	    </p>
	    <p>
	    The problem with using a single node is the time it takes to recover the node
	    and the cost (if any) of the client reconnection. The time to recover is partly
	    influenced by how much state must be recovered and partly by the size of the
	    unavailability window that your application can tolerate.
	    </p>
	    <p>
	    Many applications don't like to wait more than (say) 1ms, 10ms or 50ms before
	    they can send their message.  In this case, you will typically want to send a
	    message _before_ the crashed node has been able to recover. You can achieve
	    this in two ways:
	    </p>
	    <ol class="plain">
	      <li>You don't care about replicating state and can use any other queue as a
	      'suitable queue'.  This is easy - just make sure the right consumers and routes
	      are wired up.
	      </li>
	      <li>You do care about replicating state. Then you can fail over to a passive
	      server – this is not available out of the box but you can  <a href="mailto:info@rabbitmq.com">
	      contact us for more info</a> (You can also do active/active failover but it
	      is much more fiddly).
	      </li>
	    </ol>
	  </doc:a>
	</doc:faq>
	
	<doc:faq name="last-message-on-topic">
	  <doc:heading>How can I retrieve the last message published to a particular topic?</doc:heading>
	  <doc:q>
	    <p>
	      A classic use-case for messaging systems is the example
	      of subscribing to a topic of, say, 'market prices' for
	      an asset. By that a client very often means, "send me
	      the last published one and then subscribe me to any
	      update". Sometimes it is not necessary if the asset is
	      liquid (MSFT) but if it is illiquid, the client should
	      receive the last available message, as it's possible
	      there will be a long delay before the next update.
	    </p>
	    <p>
	      Does RabbitMQ support this?
	    </p>
	  </doc:q>
	  <doc:a>
	    <p>
	      This is not something AMQP provides out-of-the-box,
	      although one can imagine a solution involving a trivial
	      service (a simple hash table, in effect) answering
	      requests for most-recent-price served via AMQP. The
	      client would subscribe to the stream as usual, and in
	      parallel ask the service for the most recent price.
	    </p>
	    <p>
	      Such a service could be implemented either inside the
	      RabbitMQ broker, in Erlang, thus taking advantage of
	      Erlang's distribution and high-availability properties,
	      or it could be implemented outside the broker, as a
	      regular AMQP client.
	    </p>
	    <p>
	      Mike Bridgen has created an experimental last value cache,
	      implemented using RabbitMQ's plugin exchange type. It is 
	      <a href="http://github.com/squaremo/rabbitmq-lvc-plugin">available
	      to download from github</a>.
	    </p>	    
	  </doc:a>
	</doc:faq>

	<doc:faq name="channel-encryption">
	  <doc:heading>How do I enable channel encryption with RabbitMQ?</doc:heading>
	  <doc:q>
	    <p>
	      Say I want to transfer a message across the AMQP
	      network, without depending on the target being there,
	      and that the 'channel' between the message source client
	      and the message target client should be strongly
	      encrypted and authenticated. Is this something RabbitMQ
	      provides?
	    </p>
	  </doc:q>
	  <doc:a>
	    <p>
	      There are two kinds of encryption that could be
	      supported by an AMQP implementation.
	    </p>
	    <p>
	      The first is encryption of the AMQP stream. There's no
	      provision in the standard for that, but it is possible to
	      use <a href="ssl.html">SSL with RabbitMQ</a> 
	      as of Release 1.7.0.</p>
	    <p>
	      The second kind of encryption is encryption of
	      individual messages. AMQP is silent on this front as
	      well, but using a layer of encryption in the clients is
	      very easy. Adding support for this to RabbitMQ's client
	      library would be a simple matter.
	    </p>
	  </doc:a>
	</doc:faq>

	<doc:faq name="instrumentation-logging-debugging">
	  <doc:heading>What provision is there for instrumentation, logging and debugging?</doc:heading>
	  <doc:a>
	  <p>
	  RabbitMQ uses AMQP internally to the broker to notify interested parties of significant
	  events. Administration and management exchanges are provided for tools to bind to.
	  </p>
	  <p>
	  Various management and monitoring tools are <a href="/admin-guide.html#management">available 
	  from RabbitMQ</a> and <a href="/how.html#management">the community</a>.
	  Information about logging output can be found in the <a href="/install.html">install guide</a>.
	  </p>
	  </doc:a>
	</doc:faq>

	<doc:faq name="check-queue-depth">
	  <doc:heading>How can I check the depth of a particular queue?</doc:heading>
	  <doc:a>
<p>
There are several ways you can accomplish this depending on exactly
what you want to achieve. From the command line, you can use
"rabbitmqctl list_queues" to list the queues at a particular node and
virtual host. The <a href="/rabbitmqctl.1.man.html#list_queues">rabbitmqctl documentation</a> has more
information about the various options you can use with this command.
Using AMQP, the 'queue.declare' command, which is idempotent, returns
in one of the ' <a href="&dir-current-javadoc;">queue.declare-ok</a>' 

fields the number of messages in the queue that are ready for
delivery to consumers. The same information is also returned when
fetching messages with 'basic.get', in a field of ' <a href="&dir-current-javadoc;">basic.get-ok</a>'.
</p>
<p>
As a third alternative, if you have installed the <a href="http://www.lshift.net/blog/2009/11/30/introducing-rabbitmq-status-plugin">RabbitMQ Status
Plugin</a> you can get queue depths (and lots more broker status information) over http.
</p>
	  </doc:a>
	</doc:faq>
	
	<doc:faq name="atomic-operations">
	  <doc:heading>How do I use transactions to implement atomic operations in RabbitMQ?</doc:heading>
	  <doc:a>
	  <p>
	  RabbitMQ implements AMQP's TX message class to support atomic operations
	  with clients that request them.
	  </p>
	  <p>
	  If you need only to acknowledge receipt of a message you should get the
	  consumer to send a basic.ack once its done with processing. There's no
	  need to use tx in this case.
	  </p>
	  <p>
	  However, if you need to both ack a message and publish some other messages
	  as an atomic unit then you should set tx.select on the channel to start a
	  transaction. When processing the received message, you can publish your
	  messages and ack; only when you finally call tx.commit do the
	  actions of the transaction take effect. In this case, if the consumer
	  crashes, the ack and all publications get forgotten: either all of the actions
	  happen or nothing happens.
	  </p>
	  <p>
	  If, at the application level, you realise that due to some external event
	  everything needs to be cancelled then call tx.rollback on the channel.
	  </p>
	  </doc:a>
	</doc:faq>
	
	<doc:faq name="testing-rabbit">
	  <doc:heading>How do I test RabbitMQ?</doc:heading>
	  <doc:a>
	    <p>
	      You can test the RabbitMQ broker by:
	    </p>
	    <ul class="compact">
	      <li>
		connecting to our <a
		href="examples.html#demo-server">demo server</a>
		using one of the RabbitMQ <a
		href="examples.html">example programs</a>
	      </li>
	      <li>
		connecting to our demo server using another AMQP
		0-8 compatible client
	      </li>
	      <li>
		<a href="download.html">Downloading</a> the broker
		and experimenting with it on your own machine
	      </li>
	    </ul>
	  </doc:a>
	</doc:faq>

	<doc:faq name="public-test-server">
	  <doc:heading>Can I test my AMQP client against RabbitMQ?</doc:heading>
	  <doc:a>
	    <p>
	      Yes: you can either run your client against our <a
	      href="examples.html#demo-server">public demonstration
	      server</a>, or <a href="download.html">download</a> and
	      <a href="install.html">run</a> a server of your own to
	      experiment with.
	    </p>
	  </doc:a>
	</doc:faq>

	<doc:faq name="replication-scope">
	  <doc:heading>How do I tune the scope of replication? Will it affect performance?</doc:heading>
	  <doc:a>
	    <p>
	      Since replication is used mainly to propagate routing
	      table information between Erlang nodes within a cluster,
	      it has a low impact on performance to begin with; also,
	      it is trivial to arrange for a "queue-only" Erlang node
	      to join the cluster, only able to consume from queues,
	      which can then avoid being part of the routing-table
	      replication system.
	    </p>
	  </doc:a>
	</doc:faq>

	<doc:faq name="analyse-network-traffic">
	  <doc:heading>Are there any tools are available to analyse AMQP network traffic?</doc:heading>
	  <doc:a>
	    <p>
	      There's a very basic, very simple AMQP protocol analyzer in
	      class <code>com.rabbitmq.tools.Tracer</code>. Invoke it with
	    </p>
	    <pre>runjava.sh com.rabbitmq.tools.Tracer <i>listenPort</i> <i>connectHost</i> <i>connectPort</i></pre>
	    <p>
	      <dl>
		<dt>listenPort</dt>
		<dd>port to listen for incoming AMQP connections on - defaults to 5673.</dd>
		<dt>connectHost</dt>
		<dd>hostname to use when making an outbound connection in response to an incoming connection - defaults to localhost.</dd>
		<dt>connectPort</dt>
		<dd>port number to use when making an outbound connection - defaults to 5672.</dd>
	      </dl>
	    </p>
	    <p>
	    There is also an <a href="http://wiki.wireshark.org/AMQP">AMQP plugin</a> available for <a href="http://www.wireshark.org/">Wireshark</a> .
	    </p>
	  </doc:a>
	</doc:faq>
	
	<doc:faq name="public-demonstration-broker">
	  <doc:heading>Is there a publicly available demonstration broker that I can use to experiment with
	  WAN AMQP connections?</doc:heading>
	  <doc:a>
	    <p>
	  Glad you asked – yes there is! We are hosting a demonstration RabbitMQ server that is freely
	  available for people to try out, perhaps for testing interoperation or experimenting with WAN
	  AMQP connections.
	    </p>
	    <p>
	  All supported RabbitMQ features are available on the server, including persistent storage.
	  While we intend to keep the server running for long stretches, we will be tracking RabbitMQ
	  development, so reserve the right to restart it, possibly erasing its database in the process
	  from time to time.
	    </p>
	    <p>
	  Here are the connection details:
	    </p>
	  <ul>	    
	  <li>Host: dev.rabbitmq.com</li>
	  <li>Port: 5672</li>
	  <li>Username: "guest"</li>
	  <li>Password: "guest"</li>
	  <li>Virtual Host: "/"</li>
	  </ul>	    
	    <p>
	  During debugging, you may wish to monitor the messages that are being sent through the
	  amq.rabbitmq.log topic exchange. One way of doing this is to make use of the 
	  <a href="http://hg.rabbitmq.com/rabbitmq-xmpp/raw-file/default/doc/index.html">XMPP IM
	  gateway</a> we run on dev.rabbitmq.com, by adding amq.rabbitmq.log@dev.rabbitmq.com to
	  your XMPP roster.
	    </p>
	  </doc:a>
	</doc:faq>
	
	<doc:faq name="migrate-to-another-machine">
	  <doc:heading>How do you migrate an instance of RabbitMQ to another machine?</doc:heading>
	  <doc:a>
	    <p>
	  Rabbit uses mnesia to replicate information about a broker (excluding messages), so you may
	  want to read the relevant sections about administration in the mnesia guide before doing
	  anything. Don't just copy the data directory and hope that mnesia will just magically recover
	  this, because it could well contain inode references. Also, taking Rabbit offline to do this may
	  be a good idea.
	    </p>
	    <p>
	  There is also the issue of persistent messages, which are not stored in mnesia. This needs to
	  handled separately.
	    </p>
	    <p>
	  And be aware that queue processes will not automatically be migrated.
	    </p>
	    <p>
	  And as always, if this is production data, then taking a backup is generally a prudent idea.
	    </p>
	    <p>
	  If you have done this already, then send a message to the list because I'd like to write more
	  about this question, but don't have any time.
	    </p>
	  </doc:a>
	</doc:faq>
	
	<doc:faq name="broker-to-broker-connections">
	  <doc:heading>How can I route messages directly from one RabbitMQ instance to
	  another. Does Rabbit MQ support broker to broker connections?</doc:heading>
	  <doc:a>
	    <p>
	      Yes it does! Many people have asked about this use case and we've devloped an 
	      implementation that we call <a href="http://hg.rabbitmq.com/rabbitmq-shovel/">Shovel</a>.
	      You can <a href="http://www.lshift.net/blog/2010/02/01/rabbitmq-shovel-message-relocation-equipment">read more about Shovel</a>
	      on the LShift blog.
	    </p>
	  </doc:a>
	</doc:faq>	
	
	
     </doc:section>

      <doc:section name="configuration">
	<doc:heading>RabbitMQ Configuration</doc:heading>

	<doc:faq name="which-ports-to-open">
	  <doc:heading>When running rabbitmq behind a firewall, which ports do I need to open?</doc:heading>
	  <doc:a>
	    <p>
	 5672:tcp
	    </p>
	  </doc:a>
	</doc:faq>	


	<doc:faq name="access_control">
	  <doc:heading>How do I configure access control?</doc:heading>
	  <doc:a>
	    <p>
	      Please see the section on <a
	      href="rabbitmqctl.1.man.html#Access%20control">access
	      control</a> in the <a
	      href="rabbitmqctl.1.man.html">rabbitmqctl(1) manual page</a>.
	    </p>
	  </doc:a>
	</doc:faq>	
	
     </doc:section>

      <doc:section name="performance">
	<doc:heading>Performance, Scalability &amp; Clustering</doc:heading>

	<doc:faq name="performance-latency">
	  <doc:heading>How low can latency be?</doc:heading>
	  <doc:a>
	    <p>
	      RabbitMQ operates at sub-millisecond latency in transient mode under a load of
	      10k messages per second. In persistent mode, it should be possible to achieve a
	      throughput of 3-5k messages per second stored to disk depending upon the exact
	      configuration.
	    </p>
	    <p>
	      Please <a href="mailto:info@rabbitmq.com?subject=How low can latency be">contact us</a> if
	      you would like more information relevant to your setup.
	    </p>
	  </doc:a>
	</doc:faq>

	<doc:faq name="performance-persistent">
	  <doc:heading>How fast is RabbitMQ in persistent mode?</doc:heading>
	  <doc:a>
	    <p>
	      From our testing, we expect easily-achievable
	      throughputs of 4000 persistent, non-transacted
	      one-kilobyte messages per second (Intel Pentium D,
	      2.8GHz, dual core, gigabit ethernet) from a single
	      RabbitMQ broker node writing to a single spindle.
	    </p>
	    <p>
	      Please let us know how RabbitMQ performs for you!
	    </p>
	  </doc:a>
	</doc:faq>

	<doc:faq name="performance-options">
	  <doc:heading>How do I switch off persistence/transactionality?</doc:heading>
	  <doc:a>
	    <p>
	      To disable transactionality, use an AMQP channel which
	      is not in "TX" mode (ie. do not call
	      <code>tx.select</code>). To disable message persistence,
	      set the "delivery mode" field in the
	      <code>basic</code>-class properties for the message to
	      either absent or to one, as mode two enables
	      persistence.
	    </p>
	  </doc:a>
	</doc:faq>

	<doc:faq name="multiple-instances">
	  <doc:heading>How you do run multiple instances of RabbitMQ?</doc:heading>
	  <doc:a>
	    <p>
	      Have you read the <a href="clustering.html">clustering guide</a>?
	    </p>
	  </doc:a>
	</doc:faq>
	
	<doc:faq name="clustering-scalability">
	  <doc:heading>How does RabbitMQ's performance scale with clustering?</doc:heading>
	  <doc:a>
	    <p>
	      Based on typical OTP application scalability, we expect
	      close-to-linear scaling.
	    </p>
	  </doc:a>
	</doc:faq>

	<doc:faq name="if-RabbitMQ-instance-dies">
	  <doc:heading>What do I do if a RabbitMQ instance dies?</doc:heading>
	  <doc:a>
	    <p>
	    It depends how and why it died, of course. Please differentiate between a dead machine and a
	    partitioned network. One quick fix for a truly dead node may be to get a backup machine,
	    reinstall the OS and Rabbit and then just restart Rabbit with the contents of the old mnesia
	    data directory (if the disk is still ok, then you could just try slotting it in the new machine).
	    Make sure that the backup machine has the same name as the machine that died. If this
	    works, you are in luck. If not, i.e. mnesia does not seem to be recovering itself (it hangs will
	    the waiting_for_tables error message), then what you can try is to nuke the mnesia directory
	    and bring this node as part of the cluster and let it replicate itself from the other cluster
	    members. Note that this will not restart queue processes that were running on this node
	    before it crashed. But you can just re-declare the queues.
	    </p>
	  </doc:a>
	</doc:faq>	
	 	 
	<doc:faq name="how-long-to-come-back-up">
	  <doc:heading>How long does it take a node take to come back up?</doc:heading>
	  <doc:a>
	    <p>
	      <i>I know this is dependent on the number of messages to load, but is there any
	      indication you can give (such as n seconds per GB, or n seconds
	      per 1K messages...)?</i>
	    </p>
	    <p>
	      It depends on the disk bandwidth as well. A million messages in a
	      queue can take up to five minutes, although this is very much a
	      worst case scenario and we're looking at ways of making this faster.
	      For example, if know that RabbitMQ was shutdown safely then fewer
	      checks are needed on recovery. At the moment, with the new persister,
	      we're doing a very thorough fsck when we come back up. If we
	      know that we've been shutdown safely then we don't need to do that.
	      This is ongoing work.
	    </p>
	  </doc:a>
	</doc:faq>
	
	 
	<doc:faq name="corrupted-state">
	  <doc:heading>Can a node's state get corrupted such that it cannot come back online? 
	  Is there a recovery tool? </doc:heading>
	  <doc:a>
	    <p>
	      State is only stored on disk if it must be recoverable. For
	      durable queues / exchanges / bindings, we use mnesia. If mnesia
	      is unable to start and read in the tables recording this
	      information then RabbitMQ cannot start or recover those queues /
	      exchanges / bindings.
	    </p>
	    <p>
	      With the new persister, RabbitMQ manages the storage of
	      all message content on disk itself. The recovery routines for
	      these are robust and do their best to recover as much as
	      possible. If corruption occurs, RabbitMQ will recover what it can,
	      and continue to start up normally.
	    </p>
	  </doc:a>
	</doc:faq>	
	
	 
	<doc:faq name="corrupted-state">
	  <doc:heading>Is there any reasonably viable metric surrounding the MTBF of a node? </doc:heading>
	  <doc:a>
	    <p>
	      Currently, the main reason that RabbitMQ might die is when it gets
	      overwhelmed by messages and starved of RAM. The good news is that 
	      tith the new persister this is no longer a problem! Other than that,
	      our users almost never report crashes. The Erlang / OTP platform is
	      very stable, exhaustively battle-tested and extremely reliable.
	    </p>
	  </doc:a>
	</doc:faq>	
	

	<doc:faq name="does-clustering-replicate-messages-to-both-servers">
	  <doc:heading>Just to be sure on the clustering side of things, when I cluster RabbitMQ nodes the
	  messages get replicated to both servers, right?
	  </doc:heading>
	  <doc:a>
	    <p>
	  Although we could do this, we don't, because it's too expensive. This would mean replicating
	  every message across the network in a synchronous fashion. And not too many people really
	  need it, in the event of a Rabbit node crashing, they just replay the log for that node.
	    </p>
	    <p>
	  BBHoss started a discussion about this on IRC (look for 
	  <a href="http://dev.rabbitmq.com/irclog/index.php?date=2008-08-27">the discussion about HA and DR
	  between BBHoss and hal</a>).
	    </p>
	    <p>
	  Having said that, this may be a use case for pluggable queues, for the avail-o-nados out there
	  :-)
	    </p>
	  </doc:a>
	</doc:faq>
	
	<doc:faq name="general-scalability">
	  <doc:heading>How many virtual hosts can I run and where?</doc:heading>
	  <doc:a>
	    <p>
	      There is no hard limit to the number of virtual hosts
	      that can be configured within a RabbitMQ cluster, save
	      available disk and memory resources.
	    </p>
	    <p>
	      Virtual hosts within AMQP are decoupled from the
	      physical network layout: one virtual host can be
	      accessed from multiple clustered brokers, just as many
	      virtual hosts can be accessed within a single
	      broker. Virtual hosts act solely as a namespacing
	      mechanism for AMQP resources.
	    </p>
	    <p>We want to get to the point where one can dynamically add and remove
	    nodes to/from a cluster that represents one logical AMQP broker, for
	    both reliability and scalability (to very high numbers of nodes).</p>

	    <p>This is an important area for us, and one of the reasons we chose
	    Erlang/OTP as the implementation platform for RabbitMQ. </p>
	  </doc:a>
	</doc:faq>
	
	<doc:faq name="how-many-concurrent-connections">
	  <doc:heading>How many concurrent connections can RabbitMQ support?</doc:heading>
	  <doc:a>
	    <p>You mean concurrent TCP connections? In theory as many as the operating
	    system will give you. If there are any niggles
	    they can be sorted out quite easily.</p>

	    <p>Also note that AMQP allows you to multiplex AMQP sessions across a
	    single TCP connection.</p>
	  </doc:a>
	</doc:faq>

	<doc:faq name="maximum-throughput">
	  <doc:heading>What's the maximum bytes/second throughput of an instance?  Can scaling be used to get more bytes/second through the system?</doc:heading>
	  <doc:a>
	    <p>We are discussing testing, both functional and performance, within the
	    AMQP working group, with the idea of defining a shared set of AMQP
	    tests, and the code to implement them.</p>

	    <p>The problem is that there are many possible configurations of the test
	    infrastructure, the RabbitMQ broker, the clients, and the tests
	    themselves (e.g. AMQP supports many different forms of message
	    delivery). In order to obtain meaningful performance figures one would
	    have to specify exactly what the setup is, to the point where anybody
	    can replicate it. Even then one would get just one data point in an
	    infinite space of possible configurations, and it is generally
	    impossible to extrapolate the results from one test to other scenarios.</p>
	  </doc:a>
	</doc:faq>


	<doc:faq name="how-are-connections-secured">
	  <doc:heading>How are the connections secured?  HTTPS or something else?  What about certificate management?</doc:heading>
	  <doc:a>
	    <p>The standard only defines basic username/password authentication. There
	    are plans to extend that with SASL or some such mechanism.</p>

	    <p>It should be possible to add SSL/TLS quite trivially. Certificate
	    management would be done in a similar fashion to most other
	    SSL/TLS-enable apps.</p>
	  </doc:a>
	</doc:faq>

	<doc:faq name="is-the-wire-protocol-pure-binary">
	  <doc:heading>Is the wire protocol pure binary or is there some XML mixed in?  Slap me and point me to the documentation if the answer is obvious.</doc:heading>
	  <doc:a>
	    <p>The protocol is pure binary.</p>
	  </doc:a>
	</doc:faq>

	<doc:faq name="erlang-says-too-many-processes">
	  <doc:heading>What does it mean when Erlang says that there are too many processes?</doc:heading>
	  <doc:a>
	    <p>
	      The short answer is that you have too many Erlang processes (i.e. lightweight processes, not
	      Unix processes). The default system limit is 32767, so if you need more, start the Erlang VM
	      with the +P flag to set the maximum number of allowed processes.
	      RabbitMQ uses Erlang processes for each channel, for each connection, and for each queue
	      within the broker. If you are running into the system limit, you might be running a large
	      system, or you might be creating unnecessary resources.	    
	    </p>
	  </doc:a>
	</doc:faq>
	

	<doc:faq name="node-per-CPU-core">
	  <doc:heading>Do I need to run a RabbitMQ cluster with a node per CPU core to get optimal performance from my messaging server?</doc:heading>
	  <doc:a>
	    <p>
	      Not at all. RabbitMQ is written to take advantage of multi-core CPUs; however,
	      there are limitations. For example, a single queue is a single thread 
	      so if you are running with just one queue it's unlikely you'll utilise
	      substantially more than one CPU core.
	    </p>
	    <p>
	      That said, there are node-wide threads within Rabbit, such as the 
	      persister, and every connection and every channel have their own threads.
	      As a result, one queue with one producer sending persistent messages 
	      may well use up to, say, 2.5 cores, but it won't be possible to push that
	      wider. As you add further queues, you will be able to use more CPU cores.  
	    </p>
	  </doc:a>
	</doc:faq>
	
	<doc:faq name="limits-to-nodes">
	  <doc:heading>Are there any limits to how many nodes I can add to a cluster?</doc:heading>
	  <doc:a>
	    <p>
	      There are some. The most likely is the bandwidth to your hard disks:
	      if you are sending lots of persistent messages, and they are going
	      to disk, then the persister thread will rapidly become the bottleneck
	      as it'll max out the bandwidth of your disk drives.
	    </p>
	    <p>
	      At that point, adding additional nodes, especially by scaling out
	      to include additional machines, will be beneficial as you'll get another
	      disk controller and more disks. If you're not doing any persistent
	      messaging, then again, due to other per-node processes becoming
	      bottlenecks, it will eventually (probably after tens of thousands
	      of queues) become more beneficial to add additional machines and
	      nodes rather than additional CPU cores to one machine.
	    </p>
	  </doc:a>
	</doc:faq>
	
	
	<doc:faq name="scaling-and-different-latency-networks">
	  <doc:heading>How is scaling affected by node distribution over different latency networks, e.g. WAN vs LAN?</doc:heading>
	  <doc:a>
	    <p>
	      High latency WANs will hurt performance for operations involving
	      mnesia transactions. This pretty much amounts to any modification
	      of topology: queue add/delete, exchange add/delete, binding
	      add/delete. Publishes and get/consume are unaffected.
	    </p>
	  </doc:a>
	</doc:faq>
	
	
	<doc:faq name="if-node-goes-down">
	  <doc:heading>If a node goes down or becomes unreachable what effects can this 
	  have on the cluster? Do things 'hang' for a bit?</doc:heading>
	  <doc:a>
	    <p>
	      Topology change operations (<a href="#scaling-and-different-latency-networks">see above</a>) 
	      could potentially pause operation for a brief time but they will complete eventually. We use
	      the net_kernel erlang module to do monitoring between nodes. The
	      default "tick" time there is 60 seconds but this can be
	      reduced. Further, in the event of a failure, any communication
	      between the nodes will likely result in an error being generated
	      and detected immediately: i.e. the only time at which you would
	      not know about a node failure for 60 seconds is if there was no
	      communication between the nodes for that amount of time.
	    </p>
	  </doc:a>
	</doc:faq>
	
	
	<doc:faq name="network-outage">
	  <doc:heading>What happens to messages when a network outage removes 
	  the route between an exchange and a bound queue? </doc:heading>
	  <doc:a>
	    <p>
	      In the event of a network brownout between two nodes in a
	      cluster, the cluster will fail. At that point, each node is
	      unable to see the queues on the other node. Thus messages will
	      silently be dropped. 
	    </p>
	    <p>
	    You can set the mandatory flag on basic.publish which will result
	    in the publisher receiving an error message should the message be
	    unable to be routed to a queue.
	    </p>
	  </doc:a>
	</doc:faq>	
	
	<doc:faq name="meldown-scenario">
	  <doc:heading>Does an entire cluster ever 'go bad' (meltdown scenario)?</doc:heading>
	  <doc:a>
	    <p>
	     Not that we've ever seen. 
	    </p>
	  </doc:a>
	</doc:faq>
	
	<doc:faq name="redundancy-at-broker-level">
	  <doc:heading>What advantages/disadvantages are there to having redundancy at the 
	  broker, rather than node, level? </doc:heading>
	  <doc:a>
	    <p>
	      Replicated brokers allow you to do active/active HA
	      setups. However, you have to manually ensure that the topology of
	      the brokers is kept the same and you must manually do
	      deduplification on the consumers. This is very much a RAID-1
	      style solution. Clusters, on the other hand, are closer to RAID-0
	      from the point of view of queues, but exchanges and bindings are
	      replicated to every node in the cluster.
	    </p>
	  </doc:a>
	</doc:faq>
	
	<doc:faq name="who-owns-what">
	  <doc:heading>If two nodes are started as separate brokers then joined into a cluster
	  and then split up again, who owns what? </doc:heading>
	  <doc:a>
	    <p>
	      It's true that the composition of a cluster can be altered
	      dynamically, however, a node must be "reset" before it can join
	      a cluster. Resetting a node removes all queues / exchanges /
	      bindings / messages from the node. When a node leaves a cluster
	      it must also be reset before it can become a standalone node. If
	      the node leaves a cluster due to all the other nodes dying, then
	      it'll continue to operate with all the exchanges the cluster had,
	      and the queues that were on the node. Bindings to those queues
	      will be maintained.
	    </p>
	  </doc:a>
	</doc:faq>	
	
	<doc:faq name="nodes-in-cluster-balance-load">
	  <doc:heading>In your clustering guide, it says that nodes in a cluster perform some
	  basic load balancing. Can you explain a bit more about this works?</doc:heading>
	  <doc:a>
	    <p>
	      Right. It's very basic. Nodes can respond to a client connection attempt
	      with AMQP's connection.redirect method (unless the client supressed
	      redirection by setting the insist flag in connection.open. Currently, we
	      do this by looking at the load average of each node and picking the least
	      loaded. This is not ideal and in some cases is suboptimal. For example,
	      when the redirected client goes on to consume from a queue on a different node.
	      We should point out that the redirect ability of AMQP disappears in 0-91
	      as it's really not the job of AMQP to be doing this. 
	    </p>
	  </doc:a>
	</doc:faq>	
	
	
      </doc:section>

      <doc:section name="general">
	<doc:heading>General</doc:heading>

	<doc:faq name="rabbit-pricing">
	  <doc:heading>How is RabbitMQ priced?</doc:heading>
	  <doc:a>
	    <p>
	      RabbitMQ is free software in both the gratis and libre
	      senses, licensed under the <a href="mpl.html">Mozilla
	      Public License</a>.
	    </p>
	  </doc:a>
	</doc:faq>

	<doc:faq name="support-options">
	  <doc:heading>What support options are available for RabbitMQ?</doc:heading>
	  <doc:a>
	    <p>
	    RabbitMQ is supported both commercially and as an open-source project. For
	    general questions please <a href="http://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">join our mailing list</a>
	    or <a href="mailto:info@rabbitmq.com">send us an email</a>.
	    </p>
	    <p>
	    Follow the links to <a href="services.html">Services</a> for information 
	    about commercial support.
	    </p>
	  </doc:a>
	</doc:faq>

	<doc:faq name="rabbit-licensing">
	  <doc:heading>How is RabbitMQ licensed (for redistribution, etc.)?</doc:heading>
	  <doc:a>
	    <p>
	      RabbitMQ is distributed under the open-source <a
	      href="mpl.html">Mozilla Public License</a>.
	    </p>
	    <p>
	      If you would like to explore other licensing options,
	      please get in touch with us by emailing <a
	      href="mailto:info@rabbitmq.com">info@rabbitmq.com</a>.
	    </p>
	  </doc:a>
	</doc:faq>

	<doc:faq name="contribution">
	  <doc:heading>How do I contribute to the RabbitMQ project?</doc:heading>
	  <doc:a>
	    <p>
	      Welcome aboard! We love contributions - here are some
	      suggestions for what you can work on:
	    </p>
	    <p>
	      <ul class="compact">
		<li>packaging for other operating systems</li>
		<li>integration with other messaging systems</li>
		<li>integration with other management systems</li>
		<li>integration with other user and permission database systems</li>
		<li>improvements to the client, and work towards other clients</li>
		<li>new services for running with RabbitMQ, either within the broker or adjacent to it</li>
		<li>... and so on!</li>
	      </ul>
	    </p>
	    <p>
	      We're happy to hear from anyone who wants to get
	      involved or is curious about how we intend to manage the
	      project.
	    </p>
	  </doc:a>
	</doc:faq>

	<doc:faq name="version-numbering">
	  <doc:heading>How should I interpret RabbitMQ's version numbering?</doc:heading>
	  <doc:a>
	    <p>
	      RabbitMQ is versioned with the scheme
	      <code><i>major</i>.<i>minor</i>.<i>patch</i></code>.
	    </p>
            <ul>
              <li>
                <code>major</code>: This number indicates the major
                version of the software. It is only changed for
                significant alterations to the software, such as (for
                instance) a total rewrite.
              </li>
              <li>
                <code>minor</code>: A change in this number indicates
                new or significantly altered features.
              </li>
              <li>
                <code>patch</code>: This number changes to make each
                distinct packaging of the software uniquely
                numbered. Small changes such as bug-fixes or packaging
                alterations may cause a change in only the
                <code>patch</code> number.
              </li>
            </ul>
	  </doc:a>
	</doc:faq>

	<doc:faq name="rffaq">
	  <doc:heading>I have a question!</doc:heading>
	  <doc:a>
	    <p>
	      Please <a href="http://lists.rabbitmq.com">join our mailing list
	      </a> or send questions to <a href="mailto:info@rabbitmq.com">
		info@rabbitmq.com</a>. We'd love to hear from you.
	    </p>
	  </doc:a>
	</doc:faq>

      </doc:section>
    </doc:div>
  </body>
</html>
