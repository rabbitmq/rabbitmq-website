<?xml-stylesheet type="text/xml" href="page.xsl"?>
<html xmlns="http://www.w3.org/1999/xhtml"
      xmlns:doc="http://www.rabbitmq.com/namespaces/ad-hoc/doc"
      xmlns:x="http://www.rabbitmq.com/2011/extensions">
  <head>
    <title>Reliability Guide</title>
  </head>
  <body show-in-this-page="true">
      <doc:section name="overview">
        <p>
          Learn how the different levels of message delivery guarantee
          in RabbitMQ work and the various trade-offs available.
        </p>
      </doc:section>
      <doc:section name="background-info">
        <doc:heading>Pre-requisites and Recommended Reading</doc:heading>
        <p>
          We assume a solid grounding in AMQP concepts and constructs.
          If you're new to AMQP then we recommended you read the
          <a href="/tutorials/amqp-concepts.html">
            RabbitMQ Guide to AMQP Concepts
          </a>,
          <a href="http://www.rabbitmq.com/how.html">How To</a> pages
          and take the time to work through the
          <a href="/getstarted.html">RabbitMQ Tutorials</a>.
        </p>
      </doc:section>
      <doc:section name="concepts">
        <doc:subsection name="durability">
          <doc:heading>General Concepts</doc:heading>
          <h4>Durability and Persistence</h4>
          <p>
            RabbitMQ implements a number of features to handle server restarts
            without data loss. The AMQP standard has a notion of durability
            (or persistence) for Exchanges, Queues and Messages. In essense, this
            attribute has the same meaning for each: that the specified object
            will survive a restart of the broker. Whether a broker restart was
            deliberate or due to a node failure; The outcome is intended to be the
            same regardless of the reason the node fails. For queues and exchanges,
            when the <code>durable</code> flag is set upon sending the initial
            <code>queue.declare</code> or <code>exchange.declare</code> method to
            the server, the standard requires that these objects continue to
            exist after a server restart. For messages sent with the <code>delivery-mode</code>
            set to <i>persistent</i>, the standard requires the broker to
            "<i>make a best-effort to hold persistent basic messages on a reliable
            storage mechanism</i>."
          </p>
          <p>
            More details about specific flags pertaining to durability and
            persistence can be found in the
            <a href="/tutorials/amqp-concepts.html">AMQP Concepts Guide</a>.
          </p>
          <p>
            The AMQP declare method for both the exchange and queue classes is a
            declarative command. If the queue/exchange already exists, then we
            still receive <code>declare-ok</code> providing that the arguments
            given for subsequent invocations of this method are the same. As the
            spec puts it, this method will "verify the exchange exists, create
            if needed." When writing clients it is, therefore, reasonable to declare
            exchanges/queues when the applications first connects to the broker.
            This operation will only fail if the object declaration fails the
            equivalence check; See the
            <a href="/amqp-0-9-1-reference.html">AMQP Reference</a> and RabbitMQ's
            <a href="/amqp-0-9-1-errata.html">list of AMQP 0-9-1 errata</a> for
            more details.
          </p>
          <h4>Persistent Messages</h4>
          <p>
            When messages are marked as persistent, the broker is responsible
            for ensuring that they are safely held in stable storage once fully
            received. As an optimisation, the broker <em>might not persist
            a message if it can be delivered immediately</em> to a consumer,
            however messages will not be discarded even in this case, until
            an acknowledgement has been received.
          </p>
        </doc:subsection>
        <doc:subsection name="connectivity">
          <doc:heading>Connectivity, Connection and Channel errors</doc:heading>
          <p>
            Connection failures can occur at any time. When a graceful shutdown occurs,
            clients will recieve a <code>connection.close</code> message from the broker.
            Under other circumstances, the connection may be abbruptly terminated once
            the operating system networking stack detects that the peer socket is non-responsive.
            Certain classes of server error can also lead to a <code>connection-error</code>.
            Errors on a connection will cause the broker to close the connection. Errors on
            a channel however, invalidate only the channel itself and not the
            connection on which it was created.
          </p>
          <p>
            If a connection or channel terminates for <i>any</i> reason, then it is up to
            the client to re-establish it in order to continue sending or receiving messages.
            Remember, once a connection is torn down, all its channels will disappear:
            any client code relying on these channels will now need to create new channels
            once the new connection is established.
          </p>  
          <p>
            Client libraries may take various approaches to signalling channel and
            connection errors. The official Java client provides methods for adding
            a <code>ShutdownListener</code> callback on both connection and channel
            objects, and the .NET client provides the
            <code>IConnection.ConnectionShutdown</code> and
            <code>IModel.ModelShutdown</code> events for detecting connection and
            channel errors respectively.
          </p>
          <h4>Using Heartbeats</h4>
          <p>
            When the network does fail, it can take the Operating System a fairly long
            time to notice and pass this information on to running applications.
            For example, on Linux based systems, the default kernel parameters yield
            a potential delay of around 15 minutes after the first retransmission timeout.
            Firewalls can also interfere with connectivity, by closing connections that
            have been idle for a short while for example. Heartbeats ensure that disrupted
            tcp connections get detected promptly. They also keep connections alive in the
            presence of firewalls.
          </p>
          <p>
            In both the official Java and .NET clients, heartbeats are enabled by configuring
            the connection factory with the desired heartbeat interval. As with any other
            connection failure, the client may attempt to re-connect and re-establish new
            channels at any time. In RabbitMQ versions 3.0 and higher, the broker will
            attempt to negotiate heartbeats by default, though the client can veto them.
          </p>
          <h4>Consumer Cancel Notifications</h4>
          <p>
            A RabbitMQ extension to the AMQP spec, consumer cancel notifications enable
            clients to detect error conditions that would otherwise go unnoticed.
            For clients that support this extension, a <code>basic.cancel</code> will be
            sent if a queue from which the client is consuming is deleted, or in a clustered
            scenario, if the node on which the queue is located fails. This notification is
            particularly useful when consuming mirrored queues, which is covered later on.
          </p>
        </doc:subsection>
      </doc:section>
      <doc:section name="robust-data-flow">
          <doc:heading>Transferring Responsibility from Producer to Broker</doc:heading>
          <p>
            How can a producer application ensure that all operations are
            safely transferred to the broker in the face of server errors,
            connection failure, missing or incorrect object definitions,
            application logic errors and potential client failures?
          </p>
          <h4>Durable Entities, Exclusivity and Auto-Delete</h4>
          <p>
            An <code>auto-delete</code> queue will be deleted automatically
            when all consumers have finished using it. For exchanges, the concept
            is the same, with the exchange being deleted when all queues have
            finished using it.
            When a queue is declared as <code>exclusive</code>, it can only be
            accessed by the connection with which it was declared. Since we
            know that the connection could break at any time, if the loss of
            a queue (and the messages it contains) is unacceptable, then we
            should avoid making it <code>exclusive</code> or setting it to
            <code>auto-detele</code>, since we might loose the queue unintentionally.
            As the computer on which the broker is running could potentially crash
            at any time, to fully avoid data loss we must also ensure that the
            queue is marked as <code>durable</code> and the messages placed in it
            marked as <code>persistent</code>.
          </p>
          <p>
            The trade off here is that we avoid data loss at a cost to the overall
            performance of the system. Persistent messages must be written to disk,
            which carries a cost that will reduce the throughput producers are able
            to achieve.
          </p>
          <h4>Acknowledgements, Confirms and Transactions</h4>
          <p>
            Unless acknowledgements are in use (i.e., <code>no-ack=false</code>) the
            broker will <em>assume</em> success and dequeue messages immediately after
            they are delivered. This can result in message loss if, for example, the
            consumer dies (or the connection is severed) before the message can be
            fully recieved or processed. With acknowledgements enabled, the broker will
            never dequeue a message until it has seen an ACK for it, which provides a
            strong guarantee against message loss at the cost of reduced throughput
            in the consumer - which will see no further messages until previously
            delivered ones are acknowledged - and increased network traffic between
            the broker and consumers. Acknowledgements can be batched by setting the
            prefetch count using <code>basic.qos</code>, which enables clients to receive
            a number of messages (up to the prefetch count before it must send an ACK).
            Whether acknowledgements are batched or not, the broker will never dequeue
            a message until it has been acked, as long as <code>no-ack=false</code>.
          </p>
          <p>
            Transactional consumers - client's that have set <code>tx.select</code> on
            an open channel - can optionally abandon acknowledgements already sent
            to the broker, by rolling back the transaction. In this case, consumed
            messages are <em>not</em> requeued and the client can still ack/reject
            these messages in subsequent transactions. Unacked message are not automatically
            redelivered on rollback either; to have the broker resend these, the
            consumer must use <code>basic.recover</code>, at which point all unacked
            messages will be redelivered.
          </p>
          <p>
            From the producer's perspective, even with persistent messages, a broker failure
            after publication can occur before a message is persisted to disk (and the file
            system synchronised), which will cause messages to be lost. Transactions eliminate
            the risk of this happening, because a <code>commit-ok</code> reply is only sent to
            the client once those steps have been completed. In the event of a failure such as
            this, the producer must assume that unless a <code>commit-ok</code> has been seen, 
            none of the messages published during the transaction have been accepted by the
            broker and will require retransmission.
          </p>
          <p>
            AMQP transactions are intended to provide atomicity only in a single queue,
            however in RabbitMQ, transactions are <em>not</em> atomic even in a single queue.
            A fault during <code>tx.commit</code> can result in a sub-set of the publishes
            appearing in the queue after a broker restart. If the <code>common-ok</code> is
            received however, Rabbit guarantees that all messages have been either placed
            in a queue, or a <code>basic.return</code> will have been issued for them
            already. With persistent messages, the broker guarantees that the messages
            have hit the disk and <code>fsync</code> has been invoked to synchronise with the
            file system.
          </p>
          <p>
            Transactions also come with a significant cost to performance. RabbitMQ added
            an extension to the AMQP standard called confirms (aka publisher or producer
            confirms), which offer a lightweight alternative to transactions, ensure the
            same guarantees with regards message publication, but offer far superiour performance.
            Confirms are enabled by sending <code>confirm-select</code> on an
            open channel. Once the broker responds with <code>confirm-ok</code>
            then the channel is said to be <i>in confirm mode</i>.
          </p>
          <p>
            With confirms enabled on a channel, once a message is sent to the broker,
            the producer will receive a <code>basic.ack</code> once one of the following
            conditions holds:
            <ul>
              <li>an un-routable mandatory message is confirmed
              right after the <code>basic.return</code> is sent</li>
              <li>a transient message is confirmed the moment it is enqueued</li>
              <li>a persistent message is confirmed when it is persisted to disk
              or when it is consumed on every queue</li>
            </ul>
            Once a <code>basic.ack</code> arrives, the message is <em>confirmed</em>
            and the publisher can be assured that the broker has taken full
            responsibility for it. In particular, for a persistent message, the
            broker ensures that a full fsync to the filesystem takes place
            before sending the <code>basic.ack</code>, ensuring that all I/O
            buffers have been flushed to disk properly. If a <code>basic.nack</code>
            is received on a producer channel set to confirms mode, the broker is
            indicating that it could not handle the message. In this case, the
            producer should retransmit the message.
          </p>
          <p>
            Despite confirms exhibiting better performance characteristics than
            transactions, there is still a cost associated with forcing an
            <code>fsync</code> to the disk, which will reduce throughput. Network
            latency also plays a role here, as the client waits for <code>confirm-ok</code>
            to be sent back by the broker. These costs can be reduced by batching
            confirms (i.e., only waiting for confirms after a batch of publishes).
          </p>
          <p>
            Note that if a disk has write caching enabled, even calling <code>fsync</code>
            cannot guarantee that data has actually made it to permanent storage,
            in which case there is a posibility of message loss in case of server
            (e.g., hardware) failure.
          </p>
          <h4>Handling Lost ACKs</h4>
          <p>
            Whilst correct use of producer confirms guarantees against message loss, it
            is still possible for a network failure to cause message duplication.
            If one or more messages have been sent and the producer is waiting for ACKs
            (i.e., confirms) from the broker and a network error occurs, upon which the
            connection is broken, forcing the producer to re-connect. Having not seen an 
            ACK for these messages, we must re-transmit them, however it is <em>possible</em>
            that the broker did receive them <b>and</b> sent ACKs for some (or all), but all those
            ACKs en-route to the producer were lost due to the network failure. The producer
            has no choice but to re-transmit the messages, and it will be necessary for
            consumers to handle potential duplicates somehow. The application can utilise
            the AMQP Basic <code>message-id</code> field to assist with this, or use a custom
            header if the <code>shortstr</code> data type is not suitable for the application's
            purposes. Responsibility for de-duplicating messages with the same application
            specific message-id belongs with the consumer, i.e., you will have to write this
            logic yourself, based on your application's requirements.
          </p>
          <h4>Handling un-routable messages</h4>
          <p>
            AMQP provides a neat recipe for detecting situations in which a published
            message cannot be routed. When the <code>mandatory</code> flag is set on a
            <code>basic.publish</code> which cannot be routed by the broker, a
            <code>basic.return</code>, containing a reply code and textual explanation
            will be sent back to the client.
          </p>
      </doc:section>
      <doc:section name="broker-2-consumer">
        <doc:subsection name="reliable-clients">
          <doc:heading>Transfered Responsibility from Broker to Consumer</doc:heading>
          <p>
            All clients need to be prepared to handle error conditions at runtime.
            Failures can occur at various points between client and server, each of which
            requires special handling by the application developer.
          </p>
          <p>
            Consumers should be particularly aware of the effect that ACKs have on
            message consuption. Once an ACK is sent, the broker will remove the message
            from the queue, and the consumer (which ACKed the message) is not <em>fully</em>
            responsible for it. If the consumer crashes before sending an ACK, the message
            will be redelivered to another consumer as one becomes available. If the
            <code>basic.qos</code> prefetch count is set, then however many unacknowledged
            message the consumer holds, these will all be subject to the same treatment.
          </p>
          <h4>Handling lost ACKs and requesting re-delivery</h4>
          <p>
            Consumers should always be ready to handle duplicate messages, even those for
            which they have sent acknowledgements. It's possible for a consumer to send a
            <code>basic.ack</code> and the network to fail such that the ACK is not delivered.
            It is also possible for ACKs to be lost in a clustered HA configuration, when the
            node on which a queue is located fails. In this case, a promoted slave will
            requeues all messages which it considers to be pending acknowledgements, which can
            include messages for which a client has issued an ACK if the acknowledgement was
            lost on the wire before reaching the master or lost during broadcast from the master
            to the slaves.
          </p>
          <p>
            When network failures occur, clients will need to re-connect and re-establish channels.
            The same is true for clients connected to a failed node in a clustered configuration,
            who will need to connect to a surviving node in the cluster. Once connections and
            channels are re-established, if consuming from the same queue (or an HA queue that has
            failed over to a slave node), it's quite possible you will subsequently receive messages
            that have been seen previously due to lost ACKs.
          </p>
          <h4>Client Recovery</h4>
          <p>
            <code>basic.recover</code>
            
            Clients must be aware that
            attempting to acknowledge a message on a different channel from the one it was
            received on will fail.
          </p>
        </doc:subsection>
        <doc:subsection name="failover-and-recovery">
          <doc:heading>Failover and Recovery</doc:heading>
        </doc:subsection>
      </doc:secion>
      <doc:section name="distributed">
        <doc:heading>Distributed RabbitMQ</doc:heading>
        <h4>Clustering</h4>
        <p>
          In a RabbitMQ cluster, state required for broker operation is replicated across all
          nodes in the cluster. Queues behave a little diferently from other objects, residing
          only on the node that creates them, though they remain visible and reachable from all
          nodes. Queues can be replicated across a cluster using the HA/Mirrored queue policy,
          which is covered below.
        </p>
        <p>
          Nodes can join and leave a cluster dynamically at runtime. Clustered nodes can opt
          to maintain thier state in memory only, or to store it additionally on the disc as
          well. A RAM only node will loose all its state after a restart (or failure).
          At least one disk node should be running at all times to prevent data loss. If you
          stop and forcefully resetting all disc nodes in a cluster, data loss is quite likely. 
        </p>
        <p>
          The last node in a cluster to go down (i.e., stop) must be the first node to be brought
          back online, otherwise the other nodes will wait 30 seconds for it to come back online,
          then fail. If the last node to go offline cannot be brought back up, you can remove it
          using the <code>rabbitmqctl forget_cluster_node</code> command. Cluster upgrades force
          you to take all the nodes offline if migrating to a new major version (e.g., from
          3.0.3 to 3.1.0). When performing this upgrade, ensure that the last node to stop was
          a disc node and ensure you start it first to prevent any configuration 
        </p>
        <h4>Working with HA/Mirrored Queues</h4>
        <p>
          Utilising RabbitMQ's robust HA/Mirrored queues, we can tolerate node failures
          without message loss in most circumstances. As long as producers use channels
          in confirm mode and persistent messages, data integrity is <em>very</em> high.
          One area where message loss can occur however, is when a master fails and the
          eldest slave is not fully synchronised. There's little to be done about this.

          If you are consuming from a mirrored-queue with noAck=true then messages can
          always be lost, regardless of enabling HA.
        </p>
        <p>
          Consumers must still be ready to handle duplicate messages when using HA queues,
          despite the fact that clustering/HA shoots for consistency and availability from
          the CAP theorem.
          In the case where a master fails, the promoted slave considers all previous consumers
          to have been abruptly disconnected and summarily requeues all messages that are
          still pending ACKs. Clients using Rabbit's Consumer Cancel Notification extension
          will receive a notification that their subscription to the mirrored-queue has
          been abruptly cancelled.
        </p>
        <h4>Federated RabbitMQ</h4>
        <p>
          When consuming from a queue bound to a federated exchange, message loss will not
          occur providing the configuration is not using <code>noAck</code> mode. Downstream
          nodes can still fail of course. If the downstream node is part of a cluster, then
          links to upstream exchanges will be recreated on a surviving node.
        </p>
        <p>
          If you've federated the same exchange on two upstreams which are clustered and
          made the federation (internal) queues (on the two upstreams) HA/mirrored, then
          rather than having an upstream set containing connection definitions for both
          upstream nodes, you should aim for just one connection (perhaps to an upstream
          load balancer) otherwise the order of messages cannot be preserved!
        </p>
        <p>
          TODO: the docs say: " If a node fails, links to upstream exchanges will be recreated on a surviving node. "
          clarify that - which node, how is it chosen? A: At Random
          
        </p>
      </doc:section>
  </body>
</html>

